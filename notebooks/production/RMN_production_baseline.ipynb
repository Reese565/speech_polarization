{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a corpus-wide RMN with tfidf embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/rocassius/w266_final/scripts/assembly\")\n",
    "sys.path.append(\"/home/rocassius/w266_final/scripts/modeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from document import load_documents\n",
    "from constant import DOC_PRAYER_PATH, MIN_SESSION, MAX_SESSION, DOC_ALL_PATH\n",
    "from subject import subject_keywords\n",
    "\n",
    "sessions = list(range(MIN_SESSION, MAX_SESSION+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import load_pickled_object\n",
    "from rmn import *\n",
    "from rmn_data_generator import RMN_DataGenerator\n",
    "from rmn_analyzer import RMN_Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding tools\n",
    "prayer_tools_path = \"/home/rocassius/gen-data/tools/prayer_tools\"\n",
    "metadata_dict = load_pickled_object(os.path.join(prayer_tools_path, \"metadata_dict\"))\n",
    "tokenizer_dict = load_pickled_object(os.path.join(prayer_tools_path, \"tokenizer_dict\"))\n",
    "embedding_matrix = load_pickled_object(os.path.join(prayer_tools_path, \"idf_embedding_matrix\"))\n",
    "global_embedding_matrix = load_pickled_object(os.path.join(prayer_tools_path, \"embedding_matrix_wg\"))\n",
    "global_tokenizer_dict = load_pickled_object(os.path.join(prayer_tools_path, \"tokenizer_dict_wg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = embedding_matrix.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = load_documents(sessions, DOC_PRAYER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4057395, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmn = RigidRMN(dropout=0.5)\n",
    "rmn.embedding_matrix = embedding_matrix\n",
    "rmn.tokenizer_dict = tokenizer_dict\n",
    "rmn.metadata_dict = metadata_dict\n",
    "rmn.infer_embedding_matrix = global_embedding_matrix\n",
    "rmn.infer_tokenizer_dict = global_tokenizer_dict\n",
    "rmn.meta_embedding_dim = 25\n",
    "rmn.num_topics = 50\n",
    "rmn.build_model(gamma=0.1, theta=0., omega=.01, lamb=0.001, bias_reconstruct=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = docs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2\n",
    "n_folds = 10\n",
    "fold_size = data_df.shape[0] // n_folds\n",
    "index_folds = [list(range(i*fold_size, (i+1)*fold_size)) for i in range(n_folds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584/1584 [==============================] - 56s 35ms/step - loss: 0.5409\n",
      "1584/1584 [==============================] - 58s 36ms/step - loss: 0.5323\n",
      "1584/1584 [==============================] - 55s 35ms/step - loss: 0.5311\n",
      "1584/1584 [==============================] - 53s 34ms/step - loss: 0.5304\n",
      "1584/1584 [==============================] - 55s 35ms/step - loss: 0.5300\n",
      "1584/1584 [==============================] - 56s 36ms/step - loss: 0.5292\n",
      "1584/1584 [==============================] - 62s 39ms/step - loss: 0.5294\n",
      "1584/1584 [==============================] - 55s 35ms/step - loss: 0.5292\n",
      "1584/1584 [==============================] - 62s 39ms/step - loss: 0.5295\n",
      "1584/1584 [==============================] - 58s 36ms/step - loss: 0.5287\n",
      "1584/1584 [==============================] - 53s 33ms/step - loss: 0.5286\n",
      "1584/1584 [==============================] - 51s 32ms/step - loss: 0.5290\n",
      "1584/1584 [==============================] - 57s 36ms/step - loss: 0.5290\n",
      " 318/1584 [=====>........................] - ETA: 42s - loss: 0.5309"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-362:\n",
      "Process Keras_worker_ForkPoolWorker-363:\n",
      "Process Keras_worker_ForkPoolWorker-361:\n",
      "Process Keras_worker_ForkPoolWorker-365:\n",
      "Process Keras_worker_ForkPoolWorker-370:\n",
      "Process Keras_worker_ForkPoolWorker-368:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-367:\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-27da3e20288f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex_folds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRMN_DataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrmn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mrmn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Success\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m       \u001b[0;31m# Callbacks batch end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m       \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mmake_logs\u001b[0;34m(model, logs, outputs, mode, prefix)\u001b[0m\n\u001b[1;32m    177\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metrics_names'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mmetrics_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;31m# Add metric names from layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m       \u001b[0mmetrics_names\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0mmetrics_names\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mlayers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    496\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     return trackable_layer_utils.filter_empty_layer_containers(\n\u001b[0;32m--> 498\u001b[0;31m         self._layers)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mfilter_empty_layer_containers\u001b[0;34m(layer_list)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexisting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mexisting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0mfiltered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 571, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 57, in __getitem__\n",
      "    X, y = self.__data_generation(indices)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 571, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 571, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 43, in __data_generation\n",
      "    return self.rmn.prep_X(self.data_df.loc[indices], for_training=True)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 57, in __getitem__\n",
      "    X, y = self.__data_generation(indices)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 521, in prep_X\n",
      "    metadata_x = self.prep_metadata(df)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 571, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 43, in __data_generation\n",
      "    return self.rmn.prep_X(self.data_df.loc[indices], for_training=True)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 571, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 571, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 57, in __getitem__\n",
      "    X, y = self.__data_generation(indices)\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 212, in prep_metadata\n",
      "    for col in self.metadata_dict.keys()]\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 57, in __getitem__\n",
      "    X, y = self.__data_generation(indices)\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 57, in __getitem__\n",
      "    X, y = self.__data_generation(indices)\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 43, in __data_generation\n",
      "    return self.rmn.prep_X(self.data_df.loc[indices], for_training=True)\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 212, in <listcomp>\n",
      "    for col in self.metadata_dict.keys()]\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 520, in prep_X\n",
      "    vectors_y = self.prep_spans(df['document'], for_training)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 520, in prep_X\n",
      "    vectors_y = self.prep_spans(df['document'], for_training)\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 43, in __data_generation\n",
      "    return self.rmn.prep_X(self.data_df.loc[indices], for_training=True)\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 57, in __getitem__\n",
      "    X, y = self.__data_generation(indices)\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 43, in __data_generation\n",
      "    return self.rmn.prep_X(self.data_df.loc[indices], for_training=True)\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 520, in prep_X\n",
      "    vectors_y = self.prep_spans(df['document'], for_training)\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 507, in prep_spans\n",
      "    spans_y = self.tokenizer_dict['tokenize_pad'](documents)\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/token_mapping.py\", line 16, in tokenize_pad\n",
      "    tokenized = tokenizer.texts_to_sequences(documents)\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 507, in prep_spans\n",
      "    spans_y = self.tokenizer_dict['tokenize_pad'](documents)\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 520, in prep_X\n",
      "    vectors_y = self.prep_spans(df['document'], for_training)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 507, in prep_spans\n",
      "    spans_y = self.tokenizer_dict['tokenize_pad'](documents)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py\", line 279, in texts_to_sequences\n",
      "    return list(self.texts_to_sequences_generator(texts))\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/token_mapping.py\", line 16, in tokenize_pad\n",
      "    tokenized = tokenizer.texts_to_sequences(documents)\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/token_mapping.py\", line 16, in tokenize_pad\n",
      "    tokenized = tokenizer.texts_to_sequences(documents)\n",
      "Process Keras_worker_ForkPoolWorker-366:\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py\", line 310, in texts_to_sequences_generator\n",
      "    self.split)\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 507, in prep_spans\n",
      "    spans_y = self.tokenizer_dict['tokenize_pad'](documents)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py\", line 279, in texts_to_sequences\n",
      "    return list(self.texts_to_sequences_generator(texts))\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py\", line 279, in texts_to_sequences\n",
      "    return list(self.texts_to_sequences_generator(texts))\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/token_mapping.py\", line 16, in tokenize_pad\n",
      "    tokenized = tokenizer.texts_to_sequences(documents)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py\", line 58, in text_to_word_sequence\n",
      "    text = text.translate(translate_map)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 571, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py\", line 310, in texts_to_sequences_generator\n",
      "    self.split)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py\", line 312, in texts_to_sequences_generator\n",
      "    for w in seq:\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py\", line 279, in texts_to_sequences\n",
      "    return list(self.texts_to_sequences_generator(texts))\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 57, in __getitem__\n",
      "    X, y = self.__data_generation(indices)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py\", line 310, in texts_to_sequences_generator\n",
      "    self.split)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py\", line 57, in text_to_word_sequence\n",
      "    translate_map = maketrans(translate_dict)\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 43, in __data_generation\n",
      "    return self.rmn.prep_X(self.data_df.loc[indices], for_training=True)\n",
      "KeyboardInterrupt\n",
      "Process Keras_worker_ForkPoolWorker-369:\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 520, in prep_X\n",
      "    vectors_y = self.prep_spans(df['document'], for_training)\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 507, in prep_spans\n",
      "    spans_y = self.tokenizer_dict['tokenize_pad'](documents)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/token_mapping.py\", line 16, in tokenize_pad\n",
      "    tokenized = tokenizer.texts_to_sequences(documents)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 43, in __data_generation\n",
      "    return self.rmn.prep_X(self.data_df.loc[indices], for_training=True)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py\", line 279, in texts_to_sequences\n",
      "    return list(self.texts_to_sequences_generator(texts))\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 520, in prep_X\n",
      "    vectors_y = self.prep_spans(df['document'], for_training)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py\", line 320, in texts_to_sequences_generator\n",
      "    elif self.oov_token is not None:\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 571, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 511, in prep_spans\n",
      "    y = self.embedding_matrix[spans_y].mean(axis=1)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 57, in __getitem__\n",
      "    X, y = self.__data_generation(indices)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\", line 151, in _mean\n",
      "    ret = umr_sum(arr, axis, dtype, out, keepdims)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py\", line 56, in text_to_word_sequence\n",
      "    translate_dict = dict((c, split) for c in filters)\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 43, in __data_generation\n",
      "    return self.rmn.prep_X(self.data_df.loc[indices], for_training=True)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1424, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py\", line 56, in <genexpr>\n",
      "    translate_dict = dict((c, split) for c in filters)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1839, in _getitem_axis\n",
      "    return self._getitem_iterable(key, axis=axis)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1133, in _getitem_iterable\n",
      "    keyarr, indexer = self._get_listlike_indexer(key, axis, raise_missing=False)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1089, in _get_listlike_indexer\n",
      "    keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 3443, in _reindex_non_unique\n",
      "    indexer, missing = self.get_indexer_non_unique(target)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 4801, in get_indexer_non_unique\n",
      "    indexer, missing = self._engine.get_indexer_non_unique(tgt_values)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 571, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 57, in __getitem__\n",
      "    X, y = self.__data_generation(indices)\n",
      "Process Keras_worker_ForkPoolWorker-364:\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 43, in __data_generation\n",
      "    return self.rmn.prep_X(self.data_df.loc[indices], for_training=True)\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 520, in prep_X\n",
      "    vectors_y = self.prep_spans(df['document'], for_training)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-61-8ba9792cc347>\", line 511, in prep_spans\n",
      "    y = self.embedding_matrix[spans_y].mean(axis=1)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\", line 151, in _mean\n",
      "    ret = umr_sum(arr, axis, dtype, out, keepdims)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 571, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 57, in __getitem__\n",
      "    X, y = self.__data_generation(indices)\n",
      "  File \"/home/rocassius/w266_final/scripts/modeling/rmn_data_generator.py\", line 43, in __data_generation\n",
      "    return self.rmn.prep_X(self.data_df.loc[indices], for_training=True)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1424, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1839, in _getitem_axis\n",
      "    return self._getitem_iterable(key, axis=axis)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1133, in _getitem_iterable\n",
      "    keyarr, indexer = self._get_listlike_indexer(key, axis, raise_missing=False)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1089, in _get_listlike_indexer\n",
      "    keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 3443, in _reindex_non_unique\n",
      "    indexer, missing = self.get_indexer_non_unique(target)\n",
      "  File \"/home/rocassius/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 4801, in get_indexer_non_unique\n",
      "    indexer, missing = self._engine.get_indexer_non_unique(tgt_values)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "for _ in range(n_epochs):\n",
    "    data_df = data_df.sample(frac=1)\n",
    "    \n",
    "    for fold in index_folds:\n",
    "        g = RMN_DataGenerator(rmn=rmn, data_df=data_df.iloc[fold], batch_size=256)\n",
    "        rmn.model.fit_generator(g, epochs = 1, use_multiprocessing=True, workers=10)\n",
    "\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_generator = RMN_DataGenerator(rmn=rmn, data_df=docs_df.sample(1000000), batch_size=256)\n",
    "# rmn.model.fit_generator(data_generator, \n",
    "#                         epochs = 3, \n",
    "#                         use_multiprocessing=True,                        \n",
    "#                         workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_models_path = \"/home/rocassius/gen-data/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmn.save_rmn(\"SuaveRanger\", local_models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmn2 = RigidRMN(dropout=0.5)\n",
    "rmn2.embedding_matrix = embedding_matrix\n",
    "rmn2.tokenizer_dict = tokenizer_dict\n",
    "rmn2.metadata_dict = metadata_dict\n",
    "rmn2.infer_embedding_matrix = global_embedding_matrix\n",
    "rmn2.infer_tokenizer_dict = global_tokenizer_dict\n",
    "rmn2.meta_embedding_dim = 25\n",
    "rmn2.num_topics = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, save_path = \"SuaveRanger\", local_models_path\n",
    "\n",
    "# make directory for model\n",
    "model_path = os.path.join(save_path, RMN_TAG % name)\n",
    "\n",
    "# load attributes\n",
    "attributes_dict = load_pickled_object(os.path.join(model_path, ATTR))\n",
    "\n",
    "# update attributes\n",
    "rmn2.num_topics         = attributes_dict[N_TOP_KEY]\n",
    "rmn2.embedding_matrix   = attributes_dict[EMBED_KEY]\n",
    "rmn2.tokenizer_dict     = attributes_dict[TOKEN_KEY]\n",
    "rmn2.metadata_dict      = attributes_dict[META_KEY]\n",
    "rmn2.meta_embedding_dim = attributes_dict[DIM_KEY] \n",
    "\n",
    "# construct identical model architecture\n",
    "rmn2.build_model(bias_reconstruct=False)\n",
    "\n",
    "# Load weights\n",
    "rmn2.model.load_weights(os.path.join(model_path, MODEL))\n",
    "\n",
    "# build associated topic model\n",
    "rmn2.build_topic_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = RMN_Analyzer(rmn2, docs_df.sample(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 3s 295ms/step\n"
     ]
    }
   ],
   "source": [
    "analyzer.predict_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rocassius/w266_final/scripts/modeling/analysis.py:45: RuntimeWarning: divide by zero encountered in log2\n",
      "  return np.sum(p*-np.log2(p), axis=-1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0080614"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(analyzer.shannon_entropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.978, 0.   , 0.   ,\n",
       "       0.   , 0.001, 0.   , 0.   , 0.006, 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.008, 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.004, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.003, 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   ], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.topic_preds.round(3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16    2780\n",
       "42    2607\n",
       "10    2371\n",
       "22    2365\n",
       "6     2327\n",
       "30    2316\n",
       "43    2299\n",
       "35    2216\n",
       "4     2209\n",
       "9     2193\n",
       "26    2155\n",
       "19    2138\n",
       "49    2135\n",
       "17    2132\n",
       "39    2115\n",
       "32    2103\n",
       "7     2098\n",
       "27    2090\n",
       "1     2089\n",
       "23    2088\n",
       "41    2079\n",
       "31    2065\n",
       "25    2061\n",
       "47    2043\n",
       "20    2036\n",
       "21    2031\n",
       "45    2024\n",
       "44    2023\n",
       "48    2020\n",
       "37    2018\n",
       "40    1962\n",
       "3     1930\n",
       "0     1888\n",
       "33    1879\n",
       "15    1876\n",
       "34    1866\n",
       "24    1825\n",
       "18    1810\n",
       "36    1753\n",
       "12    1751\n",
       "13    1746\n",
       "29    1712\n",
       "38    1703\n",
       "11    1662\n",
       "46    1628\n",
       "14    1619\n",
       "28    1608\n",
       "8     1573\n",
       "2     1543\n",
       "5     1440\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.first_topic_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16    0.027276\n",
       "42    0.025296\n",
       "22    0.023962\n",
       "6     0.023126\n",
       "30    0.022582\n",
       "10    0.022536\n",
       "4     0.022408\n",
       "43    0.022381\n",
       "19    0.021943\n",
       "49    0.021896\n",
       "7     0.021591\n",
       "35    0.021537\n",
       "27    0.021488\n",
       "9     0.021276\n",
       "23    0.021145\n",
       "26    0.020990\n",
       "32    0.020901\n",
       "41    0.020895\n",
       "47    0.020802\n",
       "39    0.020792\n",
       "17    0.020744\n",
       "25    0.020600\n",
       "21    0.020141\n",
       "40    0.020113\n",
       "48    0.020037\n",
       "20    0.019955\n",
       "45    0.019948\n",
       "18    0.019879\n",
       "31    0.019712\n",
       "3     0.019709\n",
       "44    0.019581\n",
       "37    0.019509\n",
       "15    0.019087\n",
       "0     0.019042\n",
       "34    0.018883\n",
       "33    0.018576\n",
       "12    0.018515\n",
       "24    0.018298\n",
       "13    0.018270\n",
       "36    0.017541\n",
       "29    0.017303\n",
       "14    0.017172\n",
       "28    0.017029\n",
       "1     0.016887\n",
       "46    0.016885\n",
       "8     0.016853\n",
       "38    0.016647\n",
       "11    0.016475\n",
       "5     0.016470\n",
       "2     0.015316\n",
       "dtype: float32"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.topic_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmn.infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rocassius/w266_final/scripts/modeling/vector_math.py:34: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  Ds = np.dot(Wv, v) / (np.linalg.norm(v) * np.linalg.norm(Wv, axis = 1))\n",
      "/home/rocassius/w266_final/scripts/modeling/vector_math.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ds = np.dot(Wv, v) / (np.linalg.norm(v) * np.linalg.norm(Wv, axis = 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "\n",
      "Topic 16\n",
      "['valera', 'mediators', 'yolanda', 'dickens', 'marianne', 'laurent', 'polly', 'ziglar', 'irishmen', 'kennard']\n",
      "====================\n",
      "\n",
      "Topic 42\n",
      "['astronomical', 'montebello', 'generational', 'calif', 'mcgrory', 'dietitian', 'oceanographer', 'monnet', 'fla', 'neb']\n",
      "====================\n",
      "\n",
      "Topic 22\n",
      "['educator', 'theologian', 'jurist', 'lauded', 'fam', 'outspoken', 'chaired', 'eileen', 'critic', 'mullen']\n",
      "====================\n",
      "\n",
      "Topic 6\n",
      "['pruning', 'reconstructive', 'pinches', 'trimming', 'recertification', 'borlaug', 'gnawing', 'mastectomy', 'convalescing', 'premed']\n",
      "====================\n",
      "\n",
      "Topic 30\n",
      "['lingo', 'envelope', 'margie', 'etiquette', 'playbook', 'tic', 'eileen', 'planner', 'email', 'ibe']\n",
      "====================\n",
      "\n",
      "Topic 10\n",
      "['oef', 'ariz', 'exp', 'warming', 'rev', 'oly', 'stresses', 'accelerating', 'minn', 'emissions']\n",
      "====================\n",
      "\n",
      "Topic 4\n",
      "['griffiss', 'drinker', 'supporter', 'backer', 'chronicler', 'carswell', 'statesman', 'solomons', 'hm', 'puritan']\n",
      "====================\n",
      "\n",
      "Topic 43\n",
      "['theologian', 'yers', 'jurist', 'essayist', 'reformer', 'omi', 'isaacs', 'forecaster', 'biscet', 'grigory']\n",
      "====================\n",
      "\n",
      "Topic 19\n",
      "['infallible', 'conscientious', 'successors', 'unquestionable', 'mussolini', 'yugoslavs', 'expedient', 'tudjman', 'prohibitive', 'inaccuracy']\n",
      "====================\n",
      "\n",
      "Topic 49\n",
      "['op', 'com', 'chronicle', 'memo', 'e', 'eis', 'mail', 'filing', 'erisa', 'scottsdale']\n",
      "====================\n",
      "\n",
      "Topic 7\n",
      "['prematurity', 'plights', 'scarcities', 'sixtieth', 'spoilage', 'flame', 'overindulgence', 'creativeness', 'sows', 'wanes']\n",
      "====================\n",
      "\n",
      "Topic 35\n",
      "['agriculture', 'livestock', 'sources', 'agricultural', 'archaeological', 'source', 'defunct', 'rappahannock', 'cattle', 'late']\n",
      "====================\n",
      "\n",
      "Topic 27\n",
      "['ignacio', 'minnie', 'bertha', 'marias', 'conforming', 'mateos', 'peso', 'issuance', 'restraining', 'bondsmen']\n",
      "====================\n",
      "\n",
      "Topic 9\n",
      "['calm', 'reassure', 'informed', 'anonymity', 'tense', 'situation', 'telephonic', 'jittery', 'cordial', 'reassuring']\n",
      "====================\n",
      "\n",
      "Topic 23\n",
      "['reviews', 'honorees', 'selections', 'memoirs', 'columnists', 'essays', 'texans', 'undesignated', 'compatriots', 'canadians']\n",
      "====================\n",
      "\n",
      "Topic 26\n",
      "['kelo', 'prided', 'vainly', 'futilely', 'taney', 'lakehurst', 'infirmary', 'goethals', 'lemoore', 'thurgood']\n",
      "====================\n",
      "\n",
      "Topic 32\n",
      "['pointblank', 'tional', 'civilrights', 'shotgun', 'latenight', 'trajectory', 'palsied', 'loma', 'ters', 'interna']\n",
      "====================\n",
      "\n",
      "Topic 41\n",
      "['guise', 'est', 'credible', 'impartial', 'unmerciful', 'alert', 'maelstrom', 'unfounded', 'halfa', 'stagflation']\n",
      "====================\n",
      "\n",
      "Topic 47\n",
      "['preservationists', 'proponents', 'tort', 'extinction', 'conservationists', 'sealers', 'preservation', 'revolutionize', 'homesteaders', 'archaic']\n",
      "====================\n",
      "\n",
      "Topic 39\n",
      "['aroostook', 'sauk', 'clearwater', 'tulare', 'prog', 'dubuque', 'mennonite', 'hermitage', 'amphitheater', 'hacienda']\n",
      "====================\n",
      "\n",
      "Topic 17\n",
      "['houstonians', 'weathered', 'washingtonians', 'weary', 'harried', 'exhort', 'frail', 'suffocating', 'jittery', 'insulate']\n",
      "====================\n",
      "\n",
      "Topic 25\n",
      "['fierce', 'showdown', 'duel', 'fiercest', 'indirect', 'factional', 'improbable', 'bloodshed', 'sparking', 'lull']\n",
      "====================\n",
      "\n",
      "Topic 21\n",
      "['celebratory', 'thunderous', 'bonfires', 'stroll', 'greet', 'worshipers', 'gress', 'lit', 'vent', 'laughter']\n",
      "====================\n",
      "\n",
      "Topic 40\n",
      "['petit', 'carton', 'tassel', 'delinquency', 'rectum', 'civitan', 'prick', 'checkoff', 'quill', 'thistle']\n",
      "====================\n",
      "\n",
      "Topic 48\n",
      "['innovator', 'genius', 'knack', 'geniuses', 'hemophilia', 'talents', 'transfusion', 'wasting', 'gifted', 'fostered']\n",
      "====================\n",
      "\n",
      "Topic 20\n",
      "['scholarship', 'keegan', 'alumnus', 'accepted', 'retirement', 'coaching', 'impressed', 'gifted', 'technical', 'merit']\n",
      "====================\n",
      "\n",
      "Topic 45\n",
      "['commissioner', 'umpires', 'cricket', 'ulster', 'commissioners', 'mediators', 'disciplinary', 'sri', 'chief', 'chiefs']\n",
      "====================\n",
      "\n",
      "Topic 18\n",
      "['ebert', 'edelman', 'kessler', 'dicker', 'yugoslavian', 'pollack', 'critic', 'reinhardt', 'politicized', 'friar']\n",
      "====================\n",
      "\n",
      "Topic 31\n",
      "['ethanol', 'talladega', 'gasoline', 'drillers', 'gallon', 'turnout', 'races', 'caucuses', 'halftime', 'renewables']\n",
      "====================\n",
      "\n",
      "Topic 3\n",
      "['dissipate', 'gasline', 'brouhaha', 'amplification', 'decontrol', 'commotion', 'cincpac', 'whither', 'methinks', 'pendulum']\n",
      "====================\n",
      "\n",
      "Topic 44\n",
      "['professionally', 'credited', 'hired', 'sculptor', 'admired', 'architect', 'engraving', 'historian', 'coin', 'extensively']\n",
      "====================\n",
      "\n",
      "Topic 37\n",
      "['booms', 'smokestack', 'bb', 'evader', 'boomed', 'ordinance', 'dirge', 'xxi', 'rev', 'nb']\n",
      "====================\n",
      "\n",
      "Topic 15\n",
      "['apartment', 'rented', 'flee', 'dwelling', 'dwellers', 'cabin', 'log', 'inclined', 'condo', 'collude']\n",
      "====================\n",
      "\n",
      "Topic 0\n",
      "['jingsheng', 'signatory', 'acc', 'conform', 'lra', 'wipo', 'politburo', 'wto', 'enforcers', 'strikeouts']\n",
      "====================\n",
      "\n",
      "Topic 34\n",
      "['flickering', 'snuffed', 'torches', 'candle', 'worshiper', 'pinning', 'extinguished', 'retardant', 'flame', 'incense']\n",
      "====================\n",
      "\n",
      "Topic 33\n",
      "['nto', 'provid', 'creat', 'crosscountry', 'longmont', 'deemphasize', 'eklutna', 'glenns', 'commensurately', 'jetport']\n",
      "====================\n",
      "\n",
      "Topic 12\n",
      "['aday', 'mai', 'tak', 'formosa', 'dba', 'hedging', 'pegler', 'lynd', 'smallwood', 'ankara']\n",
      "====================\n",
      "\n",
      "Topic 24\n",
      "['yokes', 'balustrade', 'spearfish', 'embroideries', 'spars', 'battlements', 'bastions', 'rt', 'swivel', 'embossed']\n",
      "====================\n",
      "\n",
      "Topic 13\n",
      "['tf', 'messes', 'guarantors', 'tehuantepec', 'nodules', 'cartel', 'contracting', 'connived', 'breeches', 'disbanded']\n",
      "====================\n",
      "\n",
      "Topic 36\n",
      "['perpetuate', 'chino', 'indoctrinate', 'orchestrate', 'culminating', 'menachem', 'culminated', 'sadat', 'retool', 'culminate']\n",
      "====================\n",
      "\n",
      "Topic 29\n",
      "['redouble', 'vows', 'vowing', 'strive', 'pledges', 'vowed', 'vow', 'symbolize', 'avenge', 'pledging']\n",
      "====================\n",
      "\n",
      "Topic 14\n",
      "['discharges', 'reverses', 'whittled', 'pistons', 'elimination', 'effluent', 'turnovers', 'hornets', 'bradleys', 'gunners']\n",
      "====================\n",
      "\n",
      "Topic 28\n",
      "['curses', 'insults', 'poisons', 'judo', 'participates', 'brossard', 'taunts', 'andor', 'federations', 'disbarment']\n",
      "====================\n",
      "\n",
      "Topic 1\n",
      "['perpetrates', 'inject', 'divest', 'noncompliance', 'formulates', 'brossard', 'accompli', 'relegates', 'decisively', 'paints']\n",
      "====================\n",
      "\n",
      "Topic 46\n",
      "['ancs', 'scra', 'postoffice', 'hle', 'iccs', 'hese', 'yoa', 'augustines', 'lre', 'tfe']\n",
      "====================\n",
      "\n",
      "Topic 8\n",
      "['alianza', 'merited', 'eminently', 'aliyev', 'quadriplegic', 'dacca', 'bollinger', 'marxian', 'fairest', 'babi']\n",
      "====================\n",
      "\n",
      "Topic 38\n",
      "['proscribes', 'perpetrates', 'inveighed', 'aggregations', 'sweepings', 'noncooperation', 'thuggery', 'hovels', 'consortiums', 'invectives']\n",
      "====================\n",
      "\n",
      "Topic 11\n",
      "['viz', 'pg', 'e', 'ch', 'doubleday', 'redacted', 'mcclatchy', 'j', 'oj', 'est']\n",
      "====================\n",
      "\n",
      "Topic 5\n",
      "['selects', 'gymnastic', 'elects', 'formulates', 'exhibiting', 'troupe', 'judo', 'superlative', 'stipulate', 'chooses']\n",
      "====================\n",
      "\n",
      "Topic 2\n",
      "['chooses', 'computes', 'selects', 'apportioned', 'dyeing', 'bumble', 'kushner', 'tendering', 'negotiates', 'predetermined']\n"
     ]
    }
   ],
   "source": [
    "analyzer.rmn.inspect_topics(analyzer.topic_use().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
