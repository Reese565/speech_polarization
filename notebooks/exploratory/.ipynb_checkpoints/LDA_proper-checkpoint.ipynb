{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Baseline\n",
    "## Training and LDA model on speaker documents from the 111th session\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "os.chdir(\"../../scripts/assembly\")\n",
    "from session_speaker_assembly import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 111th session \n",
    "s = 111\n",
    "speaker_map_df, session_phrase_df = session_phrases(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for bigrams that are considered voacbulary\n",
    "valid_phrase_df = select_phrase_classes(session_phrase_df, classes = ['vocab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_doc(df):\n",
    "    \"\"\"\n",
    "    Takes a dataframe belonging to a single speaker with the fields 'speakerid' and 'phrase_code'\n",
    "    and returns a dictionary containg their phrases and their speakerid  \n",
    "    \"\"\"\n",
    "    # Assumes every document in the df has the same speaker\n",
    "    bow_doc = {'speakerid': df.speakerid.values[0], \n",
    "               'phrase_code': list(df.phrsase_code.values)}\n",
    "    \n",
    "    return bow_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.42  seconds\n"
     ]
    }
   ],
   "source": [
    "# Create BOW docs according to the global dictionary that\n",
    "# was imported in the speaker assembly module\n",
    "import time \n",
    "start = time.time()\n",
    "bow_docs = speaker_bow_docs(valid_phrase_df)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(round(elapsed, 2), \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speakerid</th>\n",
       "      <th>phrase_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>111113931</td>\n",
       "      <td>[(423216, 1), (423439, 1), (423558, 1), (42408...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>111113951</td>\n",
       "      <td>[(452460, 1), (453117, 1), (472778, 3), (47298...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>111113981</td>\n",
       "      <td>[(425414, 4), (438903, 1), (453117, 4), (45747...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>111114011</td>\n",
       "      <td>[(425414, 2), (429414, 1), (440135, 1), (45311...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>111114021</td>\n",
       "      <td>[(440332, 1), (451618, 1), (462774, 9), (47279...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speakerid                                        phrase_code\n",
       "0  111113931  [(423216, 1), (423439, 1), (423558, 1), (42408...\n",
       "1  111113951  [(452460, 1), (453117, 1), (472778, 3), (47298...\n",
       "2  111113981  [(425414, 4), (438903, 1), (453117, 4), (45747...\n",
       "3  111114011  [(425414, 2), (429414, 1), (440135, 1), (45311...\n",
       "4  111114021  [(440332, 1), (451618, 1), (462774, 9), (47279..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viauslize it\n",
    "bow_docs_df = pd.DataFrame(bow_docs)\n",
    "bow_docs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "\n",
    "corpus =  list(bow_docs_df.phrase_code.values)\n",
    "tfidf_model = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.interfaces.TransformedCorpus"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=global_dct, passes=1, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 1 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 2 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 3 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 4 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 5 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 6 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 7 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 8 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 9 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda.print_topics():\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the topics have all the sample top words I suspect the model hasn't trained enough.\n",
    "\n",
    "One way to evaluate a model is through its coherence score. Let's calculate that now.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.0\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "cm = CoherenceModel(model=lda, corpus=corpus, coherence='u_mass')\n",
    "coherence = cm.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly the model has a coherence score of 0.\n",
    "\n",
    "We can try to retrain it with more passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_2 = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=global_dct, passes=10, workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 1 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 2 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 3 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 4 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 5 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 6 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 7 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 8 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n",
      "Topic: 9 \n",
      "Words: 0.000*\"passag jonescostigan\" + 0.000*\"passag jordan\" + 0.000*\"passag join\" + 0.000*\"passag joint\" + 0.000*\"passag jone\" + 0.000*\"passag john\" + 0.000*\"passag joneswhit\" + 0.000*\"passag judici\" + 0.000*\"passag judgment\" + 0.000*\"passag joelson\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_2.print_topics():\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.0\n"
     ]
    }
   ],
   "source": [
    "cm = CoherenceModel(model=lda_2, corpus=corpus, coherence='u_mass')\n",
    "coherence = cm.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3776"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_docs_df.phrase_code.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above means that the documents are at lease 5204 bigrams from the frist speaker. Perhaps this is too many, and the documents are saturated with too many words:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
