{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"gs://rwc1/data/\"\n",
    "# DATA_PATH = \"../../data/\"\n",
    "HB_PATH = os.path.join(DATA_PATH, \"hein-bound/\")\n",
    "\n",
    "BY_SPEAKER = \"byspeaker_2gram_%s.txt\"\n",
    "SPEAKER_MAP = \"%s_SpeakerMap.txt\"\n",
    "SPEECHES = \"speeches_%s.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      WASHINGTON, George\n",
       "1    HUNTINGTON, Benjamin\n",
       "2          SHERMAN, Roger\n",
       "3       STURGES, Jonathan\n",
       "Name: bioname, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import speeches\n",
    "speeches = pd.read_csv(os.path.join(HB_PATH, SPEECHES % '111'), sep = \"|\")\n",
    "\n",
    "# import vocab master list\n",
    "phrases_classes = pd.read_csv(os.path.join(DATA_PATH, \"vocabulary/master_list.txt\"), sep = \"|\")\n",
    "\n",
    "# improt voteview data for congressional memeber names\n",
    "voteview = pd.read_csv(os.path.join(DATA_PATH, \"voteview/congress_ideology.csv\"))\n",
    "voteview['bioname'].head(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vocab                   4525243\n",
       "stopword                1331580\n",
       "bad_syntax               918939\n",
       "co-occurring              26962\n",
       "roberts                   10990\n",
       "riddicks                   7585\n",
       "roberts_and_riddicks        819\n",
       "Name: _classify, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_classes[\"_classify\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2296875"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop phrases to search for\n",
    "phrases_classes[\"_classify\"].value_counts().sum() - phrases_classes[\"_classify\"].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual stop words from Gentzkow et al.\n",
    "manual_stopwords = ['absent','committee','gentlelady','hereabout','hereinafter','hereto','herewith' 'nay',\n",
    "'pro','sir','thereabout','therebeforn','therein','theretofore','therewithal','whereat','whereinto','whereupon',\n",
    " 'yea','adjourn','con','gentleman','hereafter','hereinbefore','heretofore','month','none','republican','speak',\n",
    " 'thereafter','thereby','thereinafter','thereunder','today','whereby','whereof','wherever','yes','ask','democrat',\n",
    " 'gentlemen','hereat','hereinto','hereunder','mr','now','say','speaker','thereagainst','therefor','thereof',\n",
    " 'thereunto','whereabouts','wherefore','whereon','wherewith','yield','can','etc','gentlewoman','hereby','hereof',\n",
    " 'hereunto','mrs','part','senator','tell','thereat','therefore','thereon','thereupon','whereafter','wherefrom',\n",
    " 'whereto','wherewithal','chairman','gentleladies','gentlewomen','herein','hereon','hereupon','nai','per','shall',\n",
    " 'thank','therebefore','therefrom','thereto','therewith','whereas','wherein','whereunder','will']\n",
    "\n",
    "# list of US states\n",
    "us_states_stopwords = [\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\n",
    "  \"Connecticut\",\"Delaware\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\n",
    "  \"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\n",
    "  \"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\n",
    "  \"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\n",
    "  \"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\n",
    "  \"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\n",
    "  \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]\n",
    "\n",
    "us_states_stopwords = [state.lower() for state in us_states_stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 1: Embedded List of Stop Phrases\n",
    "\n",
    "The initial strategy is to create an embedded list of stop phrases to search through. This involves splitting the big-gram phrases into a list of paired lists.\n",
    "\n",
    "`[['bg_par11','bg_par12'], ['bg_par21','bg_par22'],..., ['bg_parN1','bg_parN2']]`\n",
    "\n",
    "We would then take each speech and call the `split` method on it to create a list of unigrams of the speech.\n",
    "\n",
    "`speech = 'this is some speech text'`\n",
    "\n",
    "`speech.split() -> ['this','is','some','speech','text']`\n",
    "\n",
    "`speech_list = speech.split()`\n",
    "\n",
    "\n",
    "Using a for loop tracking the index `i` for each word in our speech, we check to see if the pair of unigrams \n",
    "\n",
    "`[speech_list[i], speech_list[i+1]]` is in our stop bigrams `[['bg_par11','bg_par12'], ['bg_par21','bg_par22'],..., ['bg_parN1','bg_parN2']]`\n",
    "\n",
    "See implementation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', 'hatfield'], ['0', 'mr'], ['00', 'm'], ['00', 'p'], ['000', 'amend']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# phrases_classes[phrases_classes['phrase'] == 'adam speak'] = 'madam speaker'\n",
    "\n",
    "# select stop phrases classes from Gentzkow et al.\n",
    "stop_classes = ['stopword','co-occurring','roberts','riddicks','roberts_and_riddicks']\n",
    "\n",
    "# filter based on stop_classes\n",
    "stop_phrases = phrases_classes[phrases_classes['_classify'].isin(stop_classes)]['phrase']\n",
    "\n",
    "# split phrases into embedded paired lists\n",
    "stop_phrases_emlist = stop_phrases.str.split().tolist()\n",
    "stop_phrases_emlist[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test to see how log it takes to search through our list of stop phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds elapsed for index 0 match: 5.745887756347656e-05\n",
      "Seconds elapsed for index n-1 match: 0.026239395141601562\n",
      "Ratio of longest to shortest: 456.66390041493776\n",
      "Mean time to search for non-match phrase in single speech: 5.132598435162971\n",
      "Estimated time to process session 111 speeches (minutes): 15335.177604579925\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# example of matching first phrase\n",
    "start = time.time()\n",
    "stop_phrases_emlist[0] in stop_phrases_emlist\n",
    "end = time.time()\n",
    "\n",
    "elapsed_first = end - start\n",
    "print(\"Seconds elapsed for index 0 match:\", elapsed_first)\n",
    "\n",
    "# example of searching for last phrase\n",
    "\n",
    "start = time.time()\n",
    "stop_phrases_emlist[-1:] in stop_phrases_emlist\n",
    "end = time.time()\n",
    "\n",
    "elapsed_last = end - start\n",
    "print(\"Seconds elapsed for index n-1 match:\", elapsed_last)\n",
    "print(\"Ratio of longest to shortest:\",elapsed_last/elapsed_first)\n",
    "\n",
    "# session 111 mean speech length\n",
    "mean_speech_len = speeches['speech'].str.split().apply(len).mean()\n",
    "print(\"Mean time to search for non-match phrase in single speech:\", mean_speech_len*elapsed_last)\n",
    "print(\"Estimated time to process session 111 speeches (minutes):\",\n",
    "      (speeches.shape[0]*mean_speech_len*elapsed_last)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = 120\n",
    "test_speech = speeches['speech'][j].lower()\n",
    "test_speech_list = test_speech.split()\n",
    "len(test_speech_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.075706481933594"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i in range(len(test_speech_list)-2):\n",
    "    if test_speech_list[i+1] == '.':\n",
    "        pass\n",
    "    if [test_speech_list[i],test_speech_list[i+1]] in stop_phrases_emlist:\n",
    "        del test_speech_list[i]\n",
    "        del test_speech_list[i+1]\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'madam speaker. i unanimous that during the session the 111th congress: (1) on legislative days of monday when the house convenes pursuant to house resolution 10. the house shall convene 90 minutes earlier than the time otherwise established by the resolution solely for the purpose of conducting morninghour debate. and (2) on legislative days of tuesday when the house convenes pursuant to house resolution 10: (a) before may 18. 2009. the house will convene for morninghour debate 90 minutes earlier than the time otherwise established by that resolution. and (b) after may 18. 2009. the house shall convene for morninghour debate hour than the time otherwise established by that resolution. and (3) on legislative days of monday or tuesday. when the house convenes for morninghour debate pursuant to an order other than house resolution 10. the house shall resume its 90 after the time otherwise established by that order. (4) the time for morninghour debate shall be limited to the 30 minutes allocated to each party. except that on tuesdays after may 18. 2009. the shall limited to 25 minutes allocated to each party and may not continue 10 before the hour appointed for the resumption of the session of the house. and (5) the form of proceeding for morninghour debate shall be as follows: (a) the prayer by the chaplain. the approval of the journal and the pledge of allegiance to the shall postponed until resumption of the session of the house. (b) initial and subsequent recognitions for debate shall alternate between the parties. (c) recognition shall be conferred by the speaker only pursuant to lists submitted by the majority leader and by the minority leader. (d) no may the house for longer than 5 minutes. except the majority leader. the minority leader. or the minority whip. and (e) following morninghour debate. the shall a recess pursuant to clause 12(a) of rule i until the time appointed for the resumption of the session of the house.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(test_speech_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 2: Knuth-Morris-Pratt Adaptation\n",
    "\n",
    "Sliding window across raw text that skips indicies in contracst to naive search through all indicies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 hatfield', '0 mr', '00 m', '00 p', '000 amend']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# phrases are now single sintring instead of paired list\n",
    "stop_phrases_list = stop_phrases.tolist()\n",
    "stop_phrases_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds elapsed: 1.04793119430542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "hits = []\n",
    "for k in range(len(stop_phrases_list)):\n",
    "    if stop_phrases_list[i] in test_speech:\n",
    "        hits.append(k)\n",
    "end = time.time()\n",
    "elapsed2 = end - start\n",
    "print(\"seconds elapsed:\",elapsed2)\n",
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpm_prefix(pattern):\n",
    "    \"\"\"KPM search prefix array for indices skipping\"\"\"\n",
    "    m = len(pattern)\n",
    "    pt = [0]*m\n",
    "    i = 0\n",
    "    for j in range(m-1):\n",
    "        while i > 0 and pattern[i] != pattern[j+1]:                \n",
    "            i = pt[i-1]\n",
    "        if pattern[i] == pattern[j+1]:\n",
    "            i += 1\n",
    "        pt[j+1] = i        \n",
    "    return pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpm_prefix('aaba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpm_matcher(text,pattern):\n",
    "    \"\"\"KPM matter matcher\"\"\"\n",
    "    match_indeces = []\n",
    "    n = len(text)\n",
    "    m = len(pattern)\n",
    "    pt = kpm_prefix(pattern)\n",
    "    i = 0\n",
    "    for j in range(n-1):\n",
    "        while i > -1 and pattern[i] != text[j+1]: # still creates infite loop if sequential characters are same\n",
    "            i = pt[i]\n",
    "        if pattern[i] == text[j+1]:\n",
    "            i += 1\n",
    "        if i == m:\n",
    "            match_indeces.append(j+2-m)\n",
    "            i = pt[i-1]\n",
    "    print(\"End:\", pattern)\n",
    "    return match_indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kpm_matcher('aabaacaadaabaaba','aaba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kpm_matcher('acat aacgacacagt aacgacacagt','aacacagt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = 19\n",
    "# 'acat acgacacagt acgacacagt'[f:f+len('acacagt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_phrases_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# matched_indecies = []\n",
    "# for phrase in stop_phrases_list:\n",
    "#     test_speech = re.sub(phrase, '', test_speech)\n",
    "# end = time.time()\n",
    "# elapsed = end - start\n",
    "# elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phrases_classes[phrases_classes['phrase'] == 'h con']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# matched_indecies = []\n",
    "# for phrase in stop_phrases_list:\n",
    "#     mtch_indecies = kpm_matcher(test_speech,phrase)\n",
    "#     matched_indecies.append(mtch_indecies)\n",
    "# end = time.time()\n",
    "# elapsed = end - start\n",
    "# elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
