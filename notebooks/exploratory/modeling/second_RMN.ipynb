{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an RMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../../scripts/assembly\")\n",
    "from session_speaker_assembly import *\n",
    "from preprocess import *\n",
    "from document import *\n",
    "from constant import SPEECHES, SPEAKER_MAP, HB_PATH, EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speakerid</th>\n",
       "      <th>chamber</th>\n",
       "      <th>state</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>111113931</td>\n",
       "      <td>S</td>\n",
       "      <td>IN</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>111113951</td>\n",
       "      <td>S</td>\n",
       "      <td>UT</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>111113981</td>\n",
       "      <td>S</td>\n",
       "      <td>MO</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>111114011</td>\n",
       "      <td>S</td>\n",
       "      <td>KS</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>111114021</td>\n",
       "      <td>S</td>\n",
       "      <td>KY</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>111121840</td>\n",
       "      <td>H</td>\n",
       "      <td>NV</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>111121930</td>\n",
       "      <td>H</td>\n",
       "      <td>IL</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554</td>\n",
       "      <td>111121940</td>\n",
       "      <td>H</td>\n",
       "      <td>FL</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555</td>\n",
       "      <td>111121950</td>\n",
       "      <td>H</td>\n",
       "      <td>AZ</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>556</td>\n",
       "      <td>111121960</td>\n",
       "      <td>H</td>\n",
       "      <td>NV</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>557 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     speakerid chamber state gender\n",
       "0    111113931       S    IN      M\n",
       "1    111113951       S    UT      M\n",
       "2    111113981       S    MO      M\n",
       "3    111114011       S    KS      M\n",
       "4    111114021       S    KY      M\n",
       "..         ...     ...   ...    ...\n",
       "552  111121840       H    NV      M\n",
       "553  111121930       H    IL      M\n",
       "554  111121940       H    FL      M\n",
       "555  111121950       H    AZ      F\n",
       "556  111121960       H    NV      F\n",
       "\n",
       "[557 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = 111\n",
    "speak_map_cols = ['speakerid','chamber','state','gender']\n",
    "\n",
    "speaker_map_df = pd.read_csv(os.path.join(HB_PATH,SPEAKER_MAP % session), sep = '|')[speak_map_cols]\n",
    "speaker_map_df = speaker_map_df.groupby('speakerid').last().reset_index()\n",
    "speaker_map_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speakerid</th>\n",
       "      <th>party</th>\n",
       "      <th>speech</th>\n",
       "      <th>congress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>111120160.0</td>\n",
       "      <td>D</td>\n",
       "      <td>honest and fair prosperity for the many. not j...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>111121410.0</td>\n",
       "      <td>D</td>\n",
       "      <td>put Americans back to work by investing in job...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>111116790.0</td>\n",
       "      <td>R</td>\n",
       "      <td>on this. and no one chose to yield to me at al...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>111120961.0</td>\n",
       "      <td>D</td>\n",
       "      <td>together. With the middle class struggling to ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>111119891.0</td>\n",
       "      <td>R</td>\n",
       "      <td>for all. He did it in a way where Atlanta was ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     speakerid party                                             speech  \\\n",
       "0  111120160.0     D  honest and fair prosperity for the many. not j...   \n",
       "1  111121410.0     D  put Americans back to work by investing in job...   \n",
       "2  111116790.0     R  on this. and no one chose to yield to me at al...   \n",
       "3  111120961.0     D  together. With the middle class struggling to ...   \n",
       "4  111119891.0     R  for all. He did it in a way where Atlanta was ...   \n",
       "\n",
       "   congress  \n",
       "0       111  \n",
       "1       111  \n",
       "2       111  \n",
       "3       111  \n",
       "4       111  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_df = subject_docs(session = session,\n",
    "                          speech_path = HB_PATH,\n",
    "                          min_tokens=MIN_TOKENS,\n",
    "                          span_finder=make_span_finder(\"health\", WINDOW))\n",
    "subject_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# megre speech and speaker metadata\n",
    "session_df = subject_df.merge(speaker_map_df, how = 'inner', on = 'speakerid')\n",
    "\n",
    "# ensure proper merge\n",
    "assert(subject_df.shape[0]==session_df.shape[0])\n",
    "assert(subject_df.shape[1] + len(speak_map_cols) - 1 == session_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speakerid</th>\n",
       "      <th>party</th>\n",
       "      <th>speech</th>\n",
       "      <th>congress</th>\n",
       "      <th>chamber</th>\n",
       "      <th>state</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>111120160.0</td>\n",
       "      <td>D</td>\n",
       "      <td>honest and fair prosperity for the many. not j...</td>\n",
       "      <td>111</td>\n",
       "      <td>H</td>\n",
       "      <td>CT</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>111120160.0</td>\n",
       "      <td>D</td>\n",
       "      <td>Congressman STARK. and many others for their t...</td>\n",
       "      <td>111</td>\n",
       "      <td>H</td>\n",
       "      <td>CT</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>111120160.0</td>\n",
       "      <td>D</td>\n",
       "      <td>modify the terms of mortgage loans. we will gi...</td>\n",
       "      <td>111</td>\n",
       "      <td>H</td>\n",
       "      <td>CT</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>111120160.0</td>\n",
       "      <td>D</td>\n",
       "      <td>the Nations wealthiest 1 percent. not the baro...</td>\n",
       "      <td>111</td>\n",
       "      <td>H</td>\n",
       "      <td>CT</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>111120160.0</td>\n",
       "      <td>D</td>\n",
       "      <td>struggles for equality. as well as political a...</td>\n",
       "      <td>111</td>\n",
       "      <td>H</td>\n",
       "      <td>CT</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     speakerid party                                             speech  \\\n",
       "0  111120160.0     D  honest and fair prosperity for the many. not j...   \n",
       "1  111120160.0     D  Congressman STARK. and many others for their t...   \n",
       "2  111120160.0     D  modify the terms of mortgage loans. we will gi...   \n",
       "3  111120160.0     D  the Nations wealthiest 1 percent. not the baro...   \n",
       "4  111120160.0     D  struggles for equality. as well as political a...   \n",
       "\n",
       "   congress chamber state gender  \n",
       "0       111       H    CT      M  \n",
       "1       111       H    CT      M  \n",
       "2       111       H    CT      M  \n",
       "3       111       H    CT      M  \n",
       "4       111       H    CT      M  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speakerid</th>\n",
       "      <th>party</th>\n",
       "      <th>speech</th>\n",
       "      <th>congress</th>\n",
       "      <th>chamber</th>\n",
       "      <th>state</th>\n",
       "      <th>gender</th>\n",
       "      <th>111113931.0</th>\n",
       "      <th>111113951.0</th>\n",
       "      <th>111113981.0</th>\n",
       "      <th>...</th>\n",
       "      <th>UT</th>\n",
       "      <th>VA</th>\n",
       "      <th>VI</th>\n",
       "      <th>VT</th>\n",
       "      <th>WA</th>\n",
       "      <th>WI</th>\n",
       "      <th>WV</th>\n",
       "      <th>WY</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>111120160.0</td>\n",
       "      <td>D</td>\n",
       "      <td>honest and fair prosperity for the many. not j...</td>\n",
       "      <td>111</td>\n",
       "      <td>H</td>\n",
       "      <td>CT</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>111120160.0</td>\n",
       "      <td>D</td>\n",
       "      <td>Congressman STARK. and many others for their t...</td>\n",
       "      <td>111</td>\n",
       "      <td>H</td>\n",
       "      <td>CT</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>111120160.0</td>\n",
       "      <td>D</td>\n",
       "      <td>modify the terms of mortgage loans. we will gi...</td>\n",
       "      <td>111</td>\n",
       "      <td>H</td>\n",
       "      <td>CT</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>111120160.0</td>\n",
       "      <td>D</td>\n",
       "      <td>the Nations wealthiest 1 percent. not the baro...</td>\n",
       "      <td>111</td>\n",
       "      <td>H</td>\n",
       "      <td>CT</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>111120160.0</td>\n",
       "      <td>D</td>\n",
       "      <td>struggles for equality. as well as political a...</td>\n",
       "      <td>111</td>\n",
       "      <td>H</td>\n",
       "      <td>CT</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14315</td>\n",
       "      <td>111119610.0</td>\n",
       "      <td>R</td>\n",
       "      <td>You wonder why this component would be in a he...</td>\n",
       "      <td>111</td>\n",
       "      <td>H</td>\n",
       "      <td>GA</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14316</td>\n",
       "      <td>111119610.0</td>\n",
       "      <td>R</td>\n",
       "      <td>not defend this 2.000page spaghetti plate here...</td>\n",
       "      <td>111</td>\n",
       "      <td>H</td>\n",
       "      <td>GA</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14317</td>\n",
       "      <td>111119610.0</td>\n",
       "      <td>R</td>\n",
       "      <td>party. But. instead. we have proposed positive...</td>\n",
       "      <td>111</td>\n",
       "      <td>H</td>\n",
       "      <td>GA</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14318</td>\n",
       "      <td>111119610.0</td>\n",
       "      <td>R</td>\n",
       "      <td>around him. skimming the top of his right boot...</td>\n",
       "      <td>111</td>\n",
       "      <td>H</td>\n",
       "      <td>GA</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14319</td>\n",
       "      <td>111116870.0</td>\n",
       "      <td>R</td>\n",
       "      <td>infrastructure of America in this bill is goin...</td>\n",
       "      <td>111</td>\n",
       "      <td>H</td>\n",
       "      <td>IL</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14320 rows × 603 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         speakerid party                                             speech  \\\n",
       "0      111120160.0     D  honest and fair prosperity for the many. not j...   \n",
       "1      111120160.0     D  Congressman STARK. and many others for their t...   \n",
       "2      111120160.0     D  modify the terms of mortgage loans. we will gi...   \n",
       "3      111120160.0     D  the Nations wealthiest 1 percent. not the baro...   \n",
       "4      111120160.0     D  struggles for equality. as well as political a...   \n",
       "...            ...   ...                                                ...   \n",
       "14315  111119610.0     R  You wonder why this component would be in a he...   \n",
       "14316  111119610.0     R  not defend this 2.000page spaghetti plate here...   \n",
       "14317  111119610.0     R  party. But. instead. we have proposed positive...   \n",
       "14318  111119610.0     R  around him. skimming the top of his right boot...   \n",
       "14319  111116870.0     R  infrastructure of America in this bill is goin...   \n",
       "\n",
       "       congress chamber state gender  111113931.0  111113951.0  111113981.0  \\\n",
       "0           111       H    CT      M            0            0            0   \n",
       "1           111       H    CT      M            0            0            0   \n",
       "2           111       H    CT      M            0            0            0   \n",
       "3           111       H    CT      M            0            0            0   \n",
       "4           111       H    CT      M            0            0            0   \n",
       "...         ...     ...   ...    ...          ...          ...          ...   \n",
       "14315       111       H    GA      M            0            0            0   \n",
       "14316       111       H    GA      M            0            0            0   \n",
       "14317       111       H    GA      M            0            0            0   \n",
       "14318       111       H    GA      M            0            0            0   \n",
       "14319       111       H    IL      M            0            0            0   \n",
       "\n",
       "       ...  UT  VA  VI  VT  WA  WI  WV  WY  F  M  \n",
       "0      ...   0   0   0   0   0   0   0   0  0  1  \n",
       "1      ...   0   0   0   0   0   0   0   0  0  1  \n",
       "2      ...   0   0   0   0   0   0   0   0  0  1  \n",
       "3      ...   0   0   0   0   0   0   0   0  0  1  \n",
       "4      ...   0   0   0   0   0   0   0   0  0  1  \n",
       "...    ...  ..  ..  ..  ..  ..  ..  ..  .. .. ..  \n",
       "14315  ...   0   0   0   0   0   0   0   0  0  1  \n",
       "14316  ...   0   0   0   0   0   0   0   0  0  1  \n",
       "14317  ...   0   0   0   0   0   0   0   0  0  1  \n",
       "14318  ...   0   0   0   0   0   0   0   0  0  1  \n",
       "14319  ...   0   0   0   0   0   0   0   0  0  1  \n",
       "\n",
       "[14320 rows x 603 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset data for prelim building\n",
    "size = session_df.shape[0]\n",
    "sample_df = session_df.iloc[:size,:]\n",
    "\n",
    "sample_df['speakerid'] = sample_df['speakerid'].astype(str)\n",
    "\n",
    "# one-hot-encode speaker metadata\n",
    "for col in speak_map_cols:\n",
    "    sample_df = pd.concat([sample_df,pd.get_dummies(sample_df[col])], axis = 1)\n",
    "    \n",
    "\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker count: 536\n"
     ]
    }
   ],
   "source": [
    "sample_speakers = sample_df['speakerid'].unique()\n",
    "print('speaker count:', len(sample_speakers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 535 Members of Congress. 100 serve in the U.S. Senate and 435 serve in the U.S. House of Representatives. A length of 50 suggests that nearly everyone commented on \"health\" (in a speech of more than 50 words) at some point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reese56/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/reese56/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/reese56/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/reese56/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/reese56/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/reese56/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building tokenizers, word indecies, and train data\n",
    "\n",
    "speech_tokenizer = Tokenizer()\n",
    "speech_tokenizer.fit_on_texts(sample_df['speech'].values)\n",
    "speeches_word_index = speech_tokenizer.word_index\n",
    "\n",
    "tokenizers = {}\n",
    "tokenizers['speech'] = {'tokenizer': speech_tokenizer,\n",
    "                        'train': speech_tokenizer.texts_to_sequences(sample_df['speech'].values),\n",
    "                        'word_index': speeches_word_index}\n",
    "\n",
    "for col in speak_map_cols:\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(sample_df[col].values)\n",
    "    tokenizers[col] = {}\n",
    "    tokenizers[col]['train'] = tokenizer.texts_to_sequences(sample_df[col].values)\n",
    "    tokenizers[col]['word_index'] = tokenizer.word_index\n",
    "    tokenizers[col]['tokenizer'] = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20409"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(speeches_word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14320"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_train = tokenizers['speech']['train']\n",
    "len(speeches_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = WINDOW + 1\n",
    "speeches_train_padded = pad_sequences(speeches_train, maxlen=max_len, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2340,     3,   843, ...,     0,     0,     0],\n",
       "       [  809,  3298,     3, ...,     0,     0,     0],\n",
       "       [ 3899,     1,   582, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  589,    39,   520, ...,     0,     0,     0],\n",
       "       [  328,   364, 20407, ...,     0,     0,     0],\n",
       "       [  622,     4,   146, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_train_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that the sentences need to be in integer-tokenized form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Iyyer et el.\n",
    "\n",
    "\"Each input to the RMN is a tuple that contains identifiers for a book and two character, as well as the spans corresponding to their relationship: $(b, c_1, c_2, S_{c_1,c_2})$. Given one such input, our objective is to reconstruct $S_(c_1,c_2)$ using a linear combination of relationship descriptors from R as shown in Figure 2; we now describe this process formally.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Needs for Baseline goal\n",
    "\n",
    "Let...\n",
    "* $s_{v_t}$ be the $t_{th}$ span of text in the span set $S_{c_1,c_2}$\n",
    "* $v_{s_t}$ be the vector that results from taking the element-wise average of the word vectors in $s_{v_t}$\n",
    "* $C$ be the set metadata embeddings\n",
    "* $m_{t,c}$ be the metadata embeddings vector for metadata $c$ with \n",
    "* $d$ be the dimension of the embedding\n",
    "* $k$ be the number of decsriptors\n",
    "\n",
    "\n",
    "Compute Sequence: Given $s_{v_t}$, do the following steps:\n",
    "1. compute avg speech vector, $v_{s_t}$,\n",
    "    * $v_{s_t} \\in \\mathbb{R}^{d}$\n",
    "2. concat avg span and metadate embeddings\n",
    "    * $ m_{t,c} \\in \\mathbb{R}^{d}$\n",
    "    * [$v_{s_t}; m_{t,1};...; m_{t,|C|}$]\n",
    "2. compute hidden state with Relu activation: \n",
    "    * $h_t =  relu \\space (W_h \\cdot [v_{s_t}; m_{t,1};...; m_{t,|C|}])$\n",
    "    * $W_h \\in \\mathbb{R}^{d \\times (d + d|C|)}$ \n",
    "    * $h_t \\in  \\mathbb{R}^{d}$\n",
    "3. get distribution over topics using another hidden layer: \n",
    "    * $d_t = softmax \\space (W_d \\cdot h_t)$\n",
    "    * $W_d \\in  \\mathbb{R}^{k \\times d}$\n",
    "    * $d_t \\in  \\mathbb{R}^{k}$\n",
    "    * $d_{t,i} \\in (0,1) \\space \\forall i$ \n",
    "4. recompose original sentence using the distribution over descriptors and the descriptor matrix:\n",
    "    * $r_t = R^Td_t$\n",
    "    * $R^T \\in \\mathbb{R}^{d \\times k}$\n",
    "    * $r_t \\in \\mathbb{R}^{d}$\n",
    "5. score distance between $r_t$ and $v_{s_t}$\n",
    "    * $distance = dist(r_t, v_{s_t})$\n",
    "    \n",
    "    \n",
    "#### Notes on implementing it with keras\n",
    "Every step that uses a matrix multiplication above can be implemented in keras using a dense layer, formatted like this:\n",
    "* `h = keras.layers.Dense(units = a, input_shape = (b, ), activation= \"the_activation\")(prev_layer)`\n",
    "    * This will make the dense layer use a weight matrix $W \\in \\mathbb{R}^{a \\times b}$, and activation \"`the_activation`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Embedding, Dense, Lambda, Input, Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GloVe embeddings are on a local VM, and are not yet in `gs://rwc1/embeddings/`. Attemtps to access embeddings from the gcloud bucket had bugs. You can find the embeddings used [here](https://nlp.stanford.edu/projects/glove/), which are the Wikipedia + Gigaword 5 trained embeddings with 6 billion tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "GLOVE_DIMS = [50, 100, 200, 300]\n",
    "EMBEDDING_DIM = GLOVE_DIMS[0]\n",
    "\n",
    "embeddings_index = {}\n",
    "glove = open('../../../glove/glove.6B.%dd.txt' % EMBEDDING_DIM)\n",
    "for line in glove:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    try:\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "    except Exception as e:\n",
    "        print(values[1:])\n",
    "        raise\n",
    "        \n",
    "    embeddings_index[word] = coefs\n",
    "glove.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(speeches_word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in speeches_word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14320, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average of spane embeddings\n",
    "Vst_train = embedding_matrix[speeches_train_padded].mean(axis=1)\n",
    "Vst_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['speakerid', 'chamber', 'state', 'gender'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot-encoded speaker metadata inputs\n",
    "\n",
    "metadata_dict = {}\n",
    "\n",
    "for col in speak_map_cols:\n",
    "    df = sample_df[sample_df[col].unique()].values\n",
    "    dim = df.shape[1]\n",
    "    metadata_dict[col] = {'input': df, 'input_dim': dim}\n",
    "\n",
    "metadata_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMN(object):\n",
    "    \n",
    "    def __init__(self, embedd_dim = 50, num_topic = 20):\n",
    "        self.embedd_dim = embedd_dim\n",
    "        self.num_topic = num_topic\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def model_loss(layer):\n",
    "\n",
    "        R = K.transpose(layer)\n",
    "\n",
    "        def custom_loss(y_true, y_pred):\n",
    "\n",
    "            hinge_loss = tf.keras.losses.hinge(y_true, y_pred)\n",
    "\n",
    "            RR_t = K.dot(R, K.transpose(R))\n",
    "            Id_mat = K.eye(EMBEDDING_DIM)\n",
    "\n",
    "            orth_penalty = K.sqrt(K.sum(K.square(RR_t - Id_mat)))\n",
    "\n",
    "            return hinge_loss + orth_penalty\n",
    "\n",
    "        return custom_loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.constraints import Constraint\n",
    "\n",
    "class Orthoganal(Constraint):\n",
    "    \"\"\"Constrains the weight matrix of a tensor's\n",
    "    hidden units to be orthogonal during optimization.\n",
    "    \n",
    "    # Args ---\n",
    "        \n",
    "        axis: axis along which orthognality condition\n",
    "        is applied. Defualt of None applies to column\n",
    "        orthogonality.\n",
    "        \n",
    "        lamb: regularization hyperparameter\"\"\"\n",
    "    \n",
    "    def __init__(self, lamb = 1.0, axis = 1,):\n",
    "        self.axis = axis\n",
    "        self.lamb = lamb\n",
    "\n",
    "    def __call__(self, w):\n",
    "        shape = w.shape\n",
    "        w = self.orthoganalize(w)\n",
    "        \n",
    "        return w\n",
    "        \n",
    "    def orthoganalize(self, w):\n",
    "        \n",
    "        if self.axis == 1:\n",
    "            w = K.transpose(w)\n",
    "            \n",
    "        RR_t = K.dot(K.transpose(w), w)\n",
    "        Id_mat = K.eye(int(RR_t.shape[0]))\n",
    "        \n",
    "        return self.lamb*K.sqrt(K.sum(K.square(RR_t - Id_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input avg span embeddings\n",
    "vt = Input(shape=(EMBEDDING_DIM,), name='Avg.Span.Embed.Input')\n",
    "\n",
    "# masking layer to account for padding\n",
    "# masking_layer = Masking(mask_value=0.0, input_shape = (EMBEDDING_DIM,), name = \"Mask\")(vt)\n",
    "\n",
    "## initializing speaker metadata embeddings\n",
    "\n",
    "input_layers = [vt]\n",
    "embedding_layers = [vt]\n",
    "for col in speak_map_cols:\n",
    "\n",
    "    # one-hot-encoded\n",
    "    input_layer = Input(shape=(metadata_dict[col]['input_dim'],), name= col + '.Embed.Input')\n",
    "    embedding_init = (Dense(units = EMBEDDING_DIM,\n",
    "                            kernel_initializer = 'glorot_normal',\n",
    "                            input_shape = (metadata_dict[col]['input_dim'], ),\n",
    "                            activation = \"linear\",\n",
    "                            name = 'C_' + col)(input_layer))\n",
    "\n",
    "    # keras embedding layers\n",
    "#     input_layer = (Embedding(output_dim = EMBEDDING_DIM,\n",
    "#                              embeddings_initializer = 'glorot_normal',\n",
    "#                             input_dim = (metadata_dict[col]['input_dim'], ),\n",
    "#                             name = 'C_' + col))\n",
    "\n",
    "    input_layers.append(input_layer)\n",
    "    embedding_layers.append(embedding_init)\n",
    "\n",
    "# concat speaker metadata embeddings\n",
    "_ht = tf.keras.layers.Concatenate(axis=1, name = 'Concat.Layer')(embedding_layers)\n",
    "\n",
    "# dense layer\n",
    "ht = Dense(units = EMBEDDING_DIM, input_shape = (_ht.shape[1], ), activation = \"relu\", name = \"Wh\")(_ht)\n",
    "\n",
    "# dense layer with softmax activation, (where previous states will eventually be inserted) \n",
    "dt = Dense(units = k, input_shape = (EMBEDDING_DIM, ), activation = \"softmax\", name = \"Wd\")(ht)\n",
    "\n",
    "# reconstruction layer\n",
    "rt = Dense(units = EMBEDDING_DIM,\n",
    "           input_shape = (k, ),\n",
    "           activation = \"linear\",\n",
    "           kernel_regularizer = Orthoganal(),\n",
    "           name = \"R\")(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model = tf.keras.Model(inputs=input_layers, outputs=rt)\n",
    "model.compile(optimizer = 'adam', loss=model_loss(rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "speakerid.Embed.Input (InputLay (None, 536)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chamber.Embed.Input (InputLayer (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "state.Embed.Input (InputLayer)  (None, 56)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gender.Embed.Input (InputLayer) (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Avg.Span.Embed.Input (InputLaye (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C_speakerid (Dense)             (None, 50)           26850       speakerid.Embed.Input[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "C_chamber (Dense)               (None, 50)           150         chamber.Embed.Input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "C_state (Dense)                 (None, 50)           2850        state.Embed.Input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "C_gender (Dense)                (None, 50)           150         gender.Embed.Input[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Concat.Layer (Concatenate)      (None, 250)          0           Avg.Span.Embed.Input[0][0]       \n",
      "                                                                 C_speakerid[0][0]                \n",
      "                                                                 C_chamber[0][0]                  \n",
      "                                                                 C_state[0][0]                    \n",
      "                                                                 C_gender[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Wh (Dense)                      (None, 50)           12550       Concat.Layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Wd (Dense)                      (None, 20)           1020        Wh[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "R (Dense)                       (None, 50)           1050        Wd[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 44,620\n",
      "Trainable params: 44,620\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "14320/14320 [==============================] - 2s 137us/sample - loss: 7.6321\n",
      "Epoch 2/3\n",
      "14320/14320 [==============================] - 2s 135us/sample - loss: 7.1708\n",
      "Epoch 3/3\n",
      "14320/14320 [==============================] - 2s 134us/sample - loss: 7.1238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f975c7b7510>"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [Vst_train]\n",
    "for key in metadata_dict.keys():\n",
    "    inputs.append(metadata_dict[key]['input'])\n",
    "\n",
    "model.fit(x=inputs, y=Vst_train, batch_size=50, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 20)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = np.transpose(model.get_layer('R').get_weights()[0])\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2477.0437"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_ = np.dot(R,np.transpose(R))\n",
    "ones_R = np.ones_like(R_)\n",
    "(np.dot(R_,np.transpose(R_)) - ones_R).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0500828 , -0.068702  , -0.04152346, ...,  0.06995886,\n",
       "         0.01937915,  0.02264922],\n",
       "       [-0.04943618, -0.06876343, -0.04118653, ...,  0.0694485 ,\n",
       "         0.0198906 ,  0.02274758],\n",
       "       [-0.04795695, -0.06738438, -0.04072453, ...,  0.06967672,\n",
       "         0.01919808,  0.02370895],\n",
       "       ...,\n",
       "       [ 0.01085086, -0.02627844,  0.04460542, ...,  0.03764527,\n",
       "         0.09563121,  0.05613044],\n",
       "       [ 0.01212826, -0.02560176,  0.0430239 , ...,  0.0382668 ,\n",
       "         0.09190331,  0.05610504],\n",
       "       [-0.02053119, -0.05172322,  0.00824339, ..., -0.06115165,\n",
       "         0.00681172,  0.02265671]], dtype=float32)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06409853,  0.00492531,  0.0194094 , ...,  0.01787162,\n",
       "        -0.01177126,  0.02901692],\n",
       "       [ 0.04692224,  0.03724405, -0.00045532, ...,  0.0137307 ,\n",
       "        -0.00253271,  0.04433429],\n",
       "       [ 0.08930108,  0.01597705,  0.03580589, ...,  0.06671582,\n",
       "        -0.00651634,  0.00475063],\n",
       "       ...,\n",
       "       [ 0.08139307,  0.01893312,  0.01637157, ...,  0.01706613,\n",
       "        -0.01064621, -0.0202357 ],\n",
       "       [ 0.03675801,  0.00944608, -0.0096072 , ..., -0.0384088 ,\n",
       "        -0.00696616, -0.03350517],\n",
       "       [ 0.04438621,  0.02955135,  0.01619193, ...,  0.03934435,\n",
       "         0.01527002,  0.05707689]])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vst_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the file drawer problem? Why is the file drawer problem important from the perspective of a firm trying to learn about the effectiveness of an intervention from peer reviewed research?\n",
    "- One response to the file drawer problem is to say, if there are multiple findings that point in the same direction, the effect is  \"real.\" What is the logic of this claim? How does p-hacking subvert this logic?\n",
    "- What is the pcurve? What is it meant to demonstrate (Figure   1). What is the key comparison to make based on Figure 1?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
