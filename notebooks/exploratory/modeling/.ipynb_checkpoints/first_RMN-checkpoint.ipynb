{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a an RMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../../scripts/assembly\")\n",
    "from session_speaker_assembly import *\n",
    "from preprocess import *\n",
    "from document import *\n",
    "from constant import SPEECHES, SPEAKER_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = subject_docs(session = 111, subject = \"health\", min_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech_id</th>\n",
       "      <th>speech</th>\n",
       "      <th>speakerid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1110000013</td>\n",
       "      <td>[today, begin, new, congress, great, time, cha...</td>\n",
       "      <td>111118060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1110000016</td>\n",
       "      <td>[retirement, savings, homes, facing, foreclosu...</td>\n",
       "      <td>111120160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1110000045</td>\n",
       "      <td>[statement, yielding, time, present, opening, ...</td>\n",
       "      <td>111121410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1110000070</td>\n",
       "      <td>[back, floor, forthwith, vote, send, senate, s...</td>\n",
       "      <td>111121410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>1110000200</td>\n",
       "      <td>[troops, fighting, two, wars, overseas, togeth...</td>\n",
       "      <td>111120961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179127</td>\n",
       "      <td>1110179128</td>\n",
       "      <td>[shined, aftermath, doubt, one, difficult, day...</td>\n",
       "      <td>111117690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179130</td>\n",
       "      <td>1110179131</td>\n",
       "      <td>[madam, speaker, rise, strong, support, james,...</td>\n",
       "      <td>111120130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179131</td>\n",
       "      <td>1110179132</td>\n",
       "      <td>[thing, support, heroes, number, agreement, to...</td>\n",
       "      <td>111120740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179160</td>\n",
       "      <td>1110179161</td>\n",
       "      <td>[government, discrimination, retaliation, fede...</td>\n",
       "      <td>111120190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179185</td>\n",
       "      <td>1110179186</td>\n",
       "      <td>[urban, areas, cover, number, percent, land, m...</td>\n",
       "      <td>111119950.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11384 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         speech_id                                             speech  \\\n",
       "12      1110000013  [today, begin, new, congress, great, time, cha...   \n",
       "15      1110000016  [retirement, savings, homes, facing, foreclosu...   \n",
       "44      1110000045  [statement, yielding, time, present, opening, ...   \n",
       "69      1110000070  [back, floor, forthwith, vote, send, senate, s...   \n",
       "199     1110000200  [troops, fighting, two, wars, overseas, togeth...   \n",
       "...            ...                                                ...   \n",
       "179127  1110179128  [shined, aftermath, doubt, one, difficult, day...   \n",
       "179130  1110179131  [madam, speaker, rise, strong, support, james,...   \n",
       "179131  1110179132  [thing, support, heroes, number, agreement, to...   \n",
       "179160  1110179161  [government, discrimination, retaliation, fede...   \n",
       "179185  1110179186  [urban, areas, cover, number, percent, land, m...   \n",
       "\n",
       "          speakerid  \n",
       "12      111118060.0  \n",
       "15      111120160.0  \n",
       "44      111121410.0  \n",
       "69      111121410.0  \n",
       "199     111120961.0  \n",
       "...             ...  \n",
       "179127  111117690.0  \n",
       "179130  111120130.0  \n",
       "179131  111120740.0  \n",
       "179160  111120190.0  \n",
       "179185  111119950.0  \n",
       "\n",
       "[11384 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_speeches = df.groupby(\"speakerid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_keys = list(speaker_speeches.groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[111113931.0,\n",
       " 111113951.0,\n",
       " 111113981.0,\n",
       " 111114011.0,\n",
       " 111114021.0,\n",
       " 111114091.0,\n",
       " 111114101.0,\n",
       " 111114121.0,\n",
       " 111114171.0,\n",
       " 111114321.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_keys[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "530"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speaker_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 535 Members of Congress. 100 serve in the U.S. Senate and 435 serve in the U.S. House of Representatives. A length of 50 suggests that nearly everyone commented on \"health\" (in a speech of more than 50 words) at some point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(df[\"speech\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'health': 1,\n",
       " 'number': 2,\n",
       " 'care': 3,\n",
       " 'bill': 4,\n",
       " 'people': 5,\n",
       " 'mr': 6,\n",
       " 'would': 7,\n",
       " 'president': 8,\n",
       " 'insurance': 9,\n",
       " 'going': 10,\n",
       " 'reform': 11,\n",
       " 'one': 12,\n",
       " 'speaker': 13,\n",
       " 'us': 14,\n",
       " 'american': 15,\n",
       " 'today': 16,\n",
       " 'government': 17,\n",
       " 'want': 18,\n",
       " 'americans': 19,\n",
       " 'know': 20,\n",
       " 'many': 21,\n",
       " 'country': 22,\n",
       " 'time': 23,\n",
       " 'legislation': 24,\n",
       " 'new': 25,\n",
       " 'years': 26,\n",
       " 'also': 27,\n",
       " 'get': 28,\n",
       " 'think': 29,\n",
       " 'senator': 30,\n",
       " 'need': 31,\n",
       " 'act': 32,\n",
       " 'congress': 33,\n",
       " 'system': 34,\n",
       " 'year': 35,\n",
       " 'percent': 36,\n",
       " 'work': 37,\n",
       " 'support': 38,\n",
       " 'jobs': 39,\n",
       " 'make': 40,\n",
       " 'important': 41,\n",
       " 'public': 42,\n",
       " 'medicare': 43,\n",
       " 'like': 44,\n",
       " 'well': 45,\n",
       " 'million': 46,\n",
       " 'national': 47,\n",
       " 'every': 48,\n",
       " 'states': 49,\n",
       " 'families': 50,\n",
       " 'program': 51,\n",
       " 'dont': 52,\n",
       " 'costs': 53,\n",
       " 'say': 54,\n",
       " 'billion': 55,\n",
       " 'education': 56,\n",
       " 'house': 57,\n",
       " 'senate': 58,\n",
       " 'services': 59,\n",
       " 'state': 60,\n",
       " 'said': 61,\n",
       " 'last': 62,\n",
       " 'small': 63,\n",
       " 'federal': 64,\n",
       " 'cost': 65,\n",
       " 'children': 66,\n",
       " 'committee': 67,\n",
       " 'take': 68,\n",
       " 'help': 69,\n",
       " 'economy': 70,\n",
       " 'america': 71,\n",
       " 'tax': 72,\n",
       " 'thank': 73,\n",
       " 'way': 74,\n",
       " 'first': 75,\n",
       " 'go': 76,\n",
       " 'amendment': 77,\n",
       " 'energy': 78,\n",
       " 'budget': 79,\n",
       " 'rise': 80,\n",
       " 'plan': 81,\n",
       " 'provide': 82,\n",
       " 'debate': 83,\n",
       " 'colleagues': 84,\n",
       " 'issue': 85,\n",
       " 'veterans': 86,\n",
       " 'much': 87,\n",
       " 'right': 88,\n",
       " 'madam': 89,\n",
       " 'money': 90,\n",
       " 'pay': 91,\n",
       " 'come': 92,\n",
       " 'economic': 93,\n",
       " 'businesses': 94,\n",
       " 'things': 95,\n",
       " 'good': 96,\n",
       " 'medical': 97,\n",
       " 'business': 98,\n",
       " 'could': 99,\n",
       " 'programs': 100,\n",
       " 'back': 101,\n",
       " 'access': 102,\n",
       " 'see': 103,\n",
       " 'floor': 104,\n",
       " 'united': 105,\n",
       " 'spending': 106,\n",
       " 'talk': 107,\n",
       " 'even': 108,\n",
       " 'fact': 109,\n",
       " 'lot': 110,\n",
       " 'benefits': 111,\n",
       " 'day': 112,\n",
       " 'women': 113,\n",
       " 'put': 114,\n",
       " 'coverage': 115,\n",
       " 'job': 116,\n",
       " 'great': 117,\n",
       " 'home': 118,\n",
       " 'nation': 119,\n",
       " 'working': 120,\n",
       " 'thats': 121,\n",
       " 'increase': 122,\n",
       " 'made': 123,\n",
       " 'trillion': 124,\n",
       " 'may': 125,\n",
       " 'must': 126,\n",
       " 'issues': 127,\n",
       " 'week': 128,\n",
       " 'passed': 129,\n",
       " 'quality': 130,\n",
       " 'talking': 131,\n",
       " 'vote': 132,\n",
       " 'look': 133,\n",
       " 'believe': 134,\n",
       " 'law': 135,\n",
       " 'funding': 136,\n",
       " 'family': 137,\n",
       " 'taxes': 138,\n",
       " 'two': 139,\n",
       " 'service': 140,\n",
       " 'nations': 141,\n",
       " 'across': 142,\n",
       " 'part': 143,\n",
       " 'side': 144,\n",
       " 'done': 145,\n",
       " 'long': 146,\n",
       " 'republican': 147,\n",
       " 'members': 148,\n",
       " 'something': 149,\n",
       " 'better': 150,\n",
       " 'chairman': 151,\n",
       " 'administration': 152,\n",
       " 'able': 153,\n",
       " 'really': 154,\n",
       " 'companies': 155,\n",
       " 'world': 156,\n",
       " 'affordable': 157,\n",
       " 'life': 158,\n",
       " 'safety': 159,\n",
       " 'create': 160,\n",
       " 'another': 161,\n",
       " 'point': 162,\n",
       " 'democrats': 163,\n",
       " 'hr': 164,\n",
       " 'community': 165,\n",
       " 'needs': 166,\n",
       " 'let': 167,\n",
       " 'opportunity': 168,\n",
       " 'republicans': 169,\n",
       " 'security': 170,\n",
       " 'majority': 171,\n",
       " 'sure': 172,\n",
       " 'since': 173,\n",
       " 'continue': 174,\n",
       " 'including': 175,\n",
       " 'seniors': 176,\n",
       " 'thing': 177,\n",
       " 'without': 178,\n",
       " 'making': 179,\n",
       " 'workers': 180,\n",
       " 'research': 181,\n",
       " 'lives': 182,\n",
       " 'financial': 183,\n",
       " 'future': 184,\n",
       " 'critical': 185,\n",
       " 'private': 186,\n",
       " 'policy': 187,\n",
       " 'leadership': 188,\n",
       " 'problem': 189,\n",
       " 'human': 190,\n",
       " 'bills': 191,\n",
       " 'unemployment': 192,\n",
       " 'millions': 193,\n",
       " 'department': 194,\n",
       " 'address': 195,\n",
       " 'food': 196,\n",
       " 'industry': 197,\n",
       " 'problems': 198,\n",
       " 'pass': 199,\n",
       " 'keep': 200,\n",
       " 'washington': 201,\n",
       " 'cant': 202,\n",
       " 'next': 203,\n",
       " 'medicaid': 204,\n",
       " 'cannot': 205,\n",
       " 'gentleman': 206,\n",
       " 'heard': 207,\n",
       " 'together': 208,\n",
       " 'ago': 209,\n",
       " 'lost': 210,\n",
       " 'strong': 211,\n",
       " 'improve': 212,\n",
       " 'change': 213,\n",
       " 'got': 214,\n",
       " 'doctors': 215,\n",
       " 'give': 216,\n",
       " 'little': 217,\n",
       " 'whether': 218,\n",
       " 'debt': 219,\n",
       " 'obama': 220,\n",
       " 'cuts': 221,\n",
       " 'actually': 222,\n",
       " 'ensure': 223,\n",
       " 'patients': 224,\n",
       " 'bipartisan': 225,\n",
       " 'colleague': 226,\n",
       " 'forward': 227,\n",
       " 'months': 228,\n",
       " 'find': 229,\n",
       " 'office': 230,\n",
       " 'already': 231,\n",
       " 'school': 232,\n",
       " 'worked': 233,\n",
       " 'around': 234,\n",
       " 'control': 235,\n",
       " 'employees': 236,\n",
       " 'dollars': 237,\n",
       " 'district': 238,\n",
       " 'use': 239,\n",
       " 'cut': 240,\n",
       " 'understand': 241,\n",
       " 'provides': 242,\n",
       " 'best': 243,\n",
       " 'water': 244,\n",
       " 'came': 245,\n",
       " 'times': 246,\n",
       " 'big': 247,\n",
       " 'communities': 248,\n",
       " 'still': 249,\n",
       " 'childrens': 250,\n",
       " 'protect': 251,\n",
       " 'democratic': 252,\n",
       " 'reduce': 253,\n",
       " 'yet': 254,\n",
       " 'individuals': 255,\n",
       " 'cancer': 256,\n",
       " 'resolution': 257,\n",
       " 'trying': 258,\n",
       " 'member': 259,\n",
       " 'deficit': 260,\n",
       " 'means': 261,\n",
       " 'current': 262,\n",
       " 'premiums': 263,\n",
       " 'three': 264,\n",
       " 'question': 265,\n",
       " 'wish': 266,\n",
       " 'efforts': 267,\n",
       " 'past': 268,\n",
       " 'takeover': 269,\n",
       " 'end': 270,\n",
       " 'seen': 271,\n",
       " 'providing': 272,\n",
       " 'speak': 273,\n",
       " 'hope': 274,\n",
       " 'friend': 275,\n",
       " 'mental': 276,\n",
       " 'disease': 277,\n",
       " 'aisle': 278,\n",
       " 'high': 279,\n",
       " 'real': 280,\n",
       " 'theyre': 281,\n",
       " 'saying': 282,\n",
       " 'afford': 283,\n",
       " 'military': 284,\n",
       " 'doctor': 285,\n",
       " 'kind': 286,\n",
       " 'says': 287,\n",
       " 'bring': 288,\n",
       " 'child': 289,\n",
       " 'clear': 290,\n",
       " 'crisis': 291,\n",
       " 'congressional': 292,\n",
       " 'major': 293,\n",
       " 'fiscal': 294,\n",
       " 'course': 295,\n",
       " 'option': 296,\n",
       " 'funds': 297,\n",
       " 'social': 298,\n",
       " 'process': 299,\n",
       " 'start': 300,\n",
       " 'stimulus': 301,\n",
       " 'citizens': 302,\n",
       " 'leader': 303,\n",
       " 'tell': 304,\n",
       " 'less': 305,\n",
       " 'month': 306,\n",
       " 'spend': 307,\n",
       " 'hard': 308,\n",
       " 'deal': 309,\n",
       " 'order': 310,\n",
       " 'place': 311,\n",
       " 'coming': 312,\n",
       " 'comes': 313,\n",
       " 'areas': 314,\n",
       " 'nearly': 315,\n",
       " 'getting': 316,\n",
       " 'im': 317,\n",
       " 'plans': 318,\n",
       " 'doesnt': 319,\n",
       " 'never': 320,\n",
       " 'almost': 321,\n",
       " 'dr': 322,\n",
       " 'proud': 323,\n",
       " 'taking': 324,\n",
       " 'try': 325,\n",
       " 'appropriations': 326,\n",
       " 'constituents': 327,\n",
       " 'several': 328,\n",
       " 'enough': 329,\n",
       " 'assistance': 330,\n",
       " 'lets': 331,\n",
       " 'body': 332,\n",
       " 'history': 333,\n",
       " 'spent': 334,\n",
       " 'simply': 335,\n",
       " 'allow': 336,\n",
       " 'example': 337,\n",
       " 'certainly': 338,\n",
       " 'report': 339,\n",
       " 'move': 340,\n",
       " 'rights': 341,\n",
       " 'provisions': 342,\n",
       " 'center': 343,\n",
       " 'weeks': 344,\n",
       " 'development': 345,\n",
       " 'weve': 346,\n",
       " 'among': 347,\n",
       " 'higher': 348,\n",
       " 'far': 349,\n",
       " 'americas': 350,\n",
       " 'labor': 351,\n",
       " 'nothing': 352,\n",
       " 'local': 353,\n",
       " 'fund': 354,\n",
       " 'face': 355,\n",
       " 'others': 356,\n",
       " 'significant': 357,\n",
       " 'drug': 358,\n",
       " 'increases': 359,\n",
       " 'might': 360,\n",
       " 'fix': 361,\n",
       " 'called': 362,\n",
       " 'days': 363,\n",
       " 'technology': 364,\n",
       " 'result': 365,\n",
       " 'recovery': 366,\n",
       " 'hear': 367,\n",
       " 'serious': 368,\n",
       " 'concerned': 369,\n",
       " 'friends': 370,\n",
       " 'ways': 371,\n",
       " 'resources': 372,\n",
       " 'lose': 373,\n",
       " 'information': 374,\n",
       " 'impact': 375,\n",
       " 'proposal': 376,\n",
       " 'used': 377,\n",
       " 'agree': 378,\n",
       " 'defense': 379,\n",
       " 'thousands': 380,\n",
       " 'according': 381,\n",
       " 'growth': 382,\n",
       " 'needed': 383,\n",
       " 'ask': 384,\n",
       " 'housing': 385,\n",
       " 'different': 386,\n",
       " 'makes': 387,\n",
       " 'particularly': 388,\n",
       " 'effort': 389,\n",
       " 'treatment': 390,\n",
       " 'raise': 391,\n",
       " 'medicine': 392,\n",
       " 'however': 393,\n",
       " 'rural': 394,\n",
       " 'step': 395,\n",
       " 'talked': 396,\n",
       " 'challenges': 397,\n",
       " 'young': 398,\n",
       " 'additional': 399,\n",
       " 'amendments': 400,\n",
       " 'taken': 401,\n",
       " 'reason': 402,\n",
       " 'save': 403,\n",
       " 'focus': 404,\n",
       " 'ever': 405,\n",
       " 'investments': 406,\n",
       " 'policies': 407,\n",
       " 'call': 408,\n",
       " 'numbers': 409,\n",
       " 'throughout': 410,\n",
       " 'didnt': 411,\n",
       " 'tobacco': 412,\n",
       " 'numberth': 413,\n",
       " 'company': 414,\n",
       " 'longterm': 415,\n",
       " 'global': 416,\n",
       " 'income': 417,\n",
       " 'group': 418,\n",
       " 'read': 419,\n",
       " 'infrastructure': 420,\n",
       " 'often': 421,\n",
       " 'secretary': 422,\n",
       " 'senators': 423,\n",
       " 'single': 424,\n",
       " 'rate': 425,\n",
       " 'went': 426,\n",
       " 'package': 427,\n",
       " 'whole': 428,\n",
       " 'away': 429,\n",
       " 'paid': 430,\n",
       " 'half': 431,\n",
       " 'appreciate': 432,\n",
       " 'told': 433,\n",
       " 'hospitals': 434,\n",
       " 'finance': 435,\n",
       " 'healthy': 436,\n",
       " 'includes': 437,\n",
       " 'always': 438,\n",
       " 'clean': 439,\n",
       " 'serve': 440,\n",
       " 'unfortunately': 441,\n",
       " 'receive': 442,\n",
       " 'least': 443,\n",
       " 'prevention': 444,\n",
       " 'provided': 445,\n",
       " 'expand': 446,\n",
       " 'middle': 447,\n",
       " 'special': 448,\n",
       " 'environment': 449,\n",
       " 'finally': 450,\n",
       " 'goes': 451,\n",
       " 'yield': 452,\n",
       " 'benefit': 453,\n",
       " 'offer': 454,\n",
       " 'schools': 455,\n",
       " 'credit': 456,\n",
       " 'uninsured': 457,\n",
       " 'choice': 458,\n",
       " 'stand': 459,\n",
       " 'savings': 460,\n",
       " 'concerns': 461,\n",
       " 'include': 462,\n",
       " 'kids': 463,\n",
       " 'decisions': 464,\n",
       " 'environmental': 465,\n",
       " 'hospital': 466,\n",
       " 'recently': 467,\n",
       " 'governmentrun': 468,\n",
       " 'paying': 469,\n",
       " 'risk': 470,\n",
       " 'homes': 471,\n",
       " 'become': 472,\n",
       " 'pleased': 473,\n",
       " 'live': 474,\n",
       " 'earlier': 475,\n",
       " 'presidents': 476,\n",
       " 'protection': 477,\n",
       " 'tonight': 478,\n",
       " 'served': 479,\n",
       " 'lower': 480,\n",
       " 'level': 481,\n",
       " 'within': 482,\n",
       " 'currently': 483,\n",
       " 'created': 484,\n",
       " 'looking': 485,\n",
       " 'especially': 486,\n",
       " 'class': 487,\n",
       " 'difficult': 488,\n",
       " 'war': 489,\n",
       " 'instead': 490,\n",
       " 'responsibility': 491,\n",
       " 'true': 492,\n",
       " 'emergency': 493,\n",
       " 'street': 494,\n",
       " 'bit': 495,\n",
       " 'second': 496,\n",
       " 'recent': 497,\n",
       " 'comprehensive': 498,\n",
       " 'necessary': 499,\n",
       " 'men': 500,\n",
       " 'abortion': 501,\n",
       " 'sector': 502,\n",
       " 'commitment': 503,\n",
       " 'discussion': 504,\n",
       " 'addition': 505,\n",
       " 'offered': 506,\n",
       " 'centers': 507,\n",
       " 'conditions': 508,\n",
       " 'matter': 509,\n",
       " 'lead': 510,\n",
       " 'everything': 511,\n",
       " 'congressman': 512,\n",
       " 'individual': 513,\n",
       " 'youre': 514,\n",
       " 'join': 515,\n",
       " 'increased': 516,\n",
       " 'living': 517,\n",
       " 'moment': 518,\n",
       " 'historic': 519,\n",
       " 'agencies': 520,\n",
       " 'add': 521,\n",
       " 'proposed': 522,\n",
       " 'couple': 523,\n",
       " 'representatives': 524,\n",
       " 'found': 525,\n",
       " 'patient': 526,\n",
       " 'attention': 527,\n",
       " 'facing': 528,\n",
       " 'meet': 529,\n",
       " 'market': 530,\n",
       " 'idea': 531,\n",
       " 'happen': 532,\n",
       " 'morning': 533,\n",
       " 'physician': 534,\n",
       " 'basic': 535,\n",
       " 'pt': 536,\n",
       " 'along': 537,\n",
       " 'struggling': 538,\n",
       " 'action': 539,\n",
       " 'association': 540,\n",
       " 'helping': 541,\n",
       " 'left': 542,\n",
       " 'age': 543,\n",
       " 'everybody': 544,\n",
       " 'given': 545,\n",
       " 'brought': 546,\n",
       " 'investment': 547,\n",
       " 'training': 548,\n",
       " 'approach': 549,\n",
       " 'terms': 550,\n",
       " 'free': 551,\n",
       " 'votes': 552,\n",
       " 'voted': 553,\n",
       " 'mean': 554,\n",
       " 'political': 555,\n",
       " 'va': 556,\n",
       " 'wanted': 557,\n",
       " 'party': 558,\n",
       " 'providers': 559,\n",
       " 'buy': 560,\n",
       " 'amount': 561,\n",
       " 'science': 562,\n",
       " 'prevent': 563,\n",
       " 'introduced': 564,\n",
       " 'maybe': 565,\n",
       " 'affairs': 566,\n",
       " 'asked': 567,\n",
       " 'cause': 568,\n",
       " 'losing': 569,\n",
       " 'largest': 570,\n",
       " 'area': 571,\n",
       " 'hours': 572,\n",
       " 'included': 573,\n",
       " 'full': 574,\n",
       " 'case': 575,\n",
       " 'yesterday': 576,\n",
       " 'kennedy': 577,\n",
       " 'role': 578,\n",
       " 'set': 579,\n",
       " 'behind': 580,\n",
       " 'early': 581,\n",
       " 'cover': 582,\n",
       " 'force': 583,\n",
       " 'advantage': 584,\n",
       " 'organizations': 585,\n",
       " 'words': 586,\n",
       " 'person': 587,\n",
       " 'urge': 588,\n",
       " 'night': 589,\n",
       " 'democrat': 590,\n",
       " 'provision': 591,\n",
       " 'anything': 592,\n",
       " 'increasing': 593,\n",
       " 'large': 594,\n",
       " 'recognize': 595,\n",
       " 'white': 596,\n",
       " 'stop': 597,\n",
       " 'choices': 598,\n",
       " 'require': 599,\n",
       " 'general': 600,\n",
       " 'upon': 601,\n",
       " 'huge': 602,\n",
       " 'importance': 603,\n",
       " 'abuse': 604,\n",
       " 'folks': 605,\n",
       " 'texas': 606,\n",
       " 'physicians': 607,\n",
       " 'concern': 608,\n",
       " 'caucus': 609,\n",
       " 'consider': 610,\n",
       " 'four': 611,\n",
       " 'rates': 612,\n",
       " 'everyone': 613,\n",
       " 'fight': 614,\n",
       " 'creating': 615,\n",
       " 'begin': 616,\n",
       " 'drugs': 617,\n",
       " 'senior': 618,\n",
       " 'opportunities': 619,\n",
       " 'york': 620,\n",
       " 'line': 621,\n",
       " 'countries': 622,\n",
       " 'run': 623,\n",
       " 'share': 624,\n",
       " 'university': 625,\n",
       " 'deserve': 626,\n",
       " 'products': 627,\n",
       " 'massive': 628,\n",
       " 'college': 629,\n",
       " 'climate': 630,\n",
       " 'changes': 631,\n",
       " 'record': 632,\n",
       " 'bad': 633,\n",
       " 'rather': 634,\n",
       " 'commerce': 635,\n",
       " 'particular': 636,\n",
       " 'rules': 637,\n",
       " 'staff': 638,\n",
       " 'chair': 639,\n",
       " 'sense': 640,\n",
       " 'greater': 641,\n",
       " 'interest': 642,\n",
       " 'improving': 643,\n",
       " 'available': 644,\n",
       " 'personal': 645,\n",
       " 'theres': 646,\n",
       " 'remember': 647,\n",
       " 'vital': 648,\n",
       " 'ability': 649,\n",
       " 'wall': 650,\n",
       " 'thought': 651,\n",
       " 'language': 652,\n",
       " 'air': 653,\n",
       " 'discuss': 654,\n",
       " 'afghanistan': 655,\n",
       " 'awareness': 656,\n",
       " 'pages': 657,\n",
       " 'yielding': 658,\n",
       " 'probably': 659,\n",
       " 'minutes': 660,\n",
       " 'fair': 661,\n",
       " 'possible': 662,\n",
       " 'facilities': 663,\n",
       " 'heart': 664,\n",
       " 'knows': 665,\n",
       " 'hearing': 666,\n",
       " 'saw': 667,\n",
       " 'wrong': 668,\n",
       " 'laws': 669,\n",
       " 'trade': 670,\n",
       " 'top': 671,\n",
       " 'agency': 672,\n",
       " 'power': 673,\n",
       " 'happened': 674,\n",
       " 'california': 675,\n",
       " 'rule': 676,\n",
       " 'priorities': 677,\n",
       " 'students': 678,\n",
       " 'chamber': 679,\n",
       " 'took': 680,\n",
       " 'subject': 681,\n",
       " 'entire': 682,\n",
       " 'rising': 683,\n",
       " 'organization': 684,\n",
       " 'absolutely': 685,\n",
       " 'subcommittee': 686,\n",
       " 'systems': 687,\n",
       " 'growing': 688,\n",
       " 'takes': 689,\n",
       " 'population': 690,\n",
       " 'prescription': 691,\n",
       " 'held': 692,\n",
       " 'death': 693,\n",
       " 'opposition': 694,\n",
       " 'nurses': 695,\n",
       " 'yes': 696,\n",
       " 'broken': 697,\n",
       " 'compensation': 698,\n",
       " 'conference': 699,\n",
       " 'though': 700,\n",
       " 'experience': 701,\n",
       " 'ought': 702,\n",
       " 'average': 703,\n",
       " 'helped': 704,\n",
       " 'toward': 705,\n",
       " 'creation': 706,\n",
       " 'per': 707,\n",
       " 'sick': 708,\n",
       " 'consumers': 709,\n",
       " 'cbo': 710,\n",
       " 'domestic': 711,\n",
       " 'situation': 712,\n",
       " 'leaders': 713,\n",
       " 'reforms': 714,\n",
       " 'freedom': 715,\n",
       " 'works': 716,\n",
       " 'piece': 717,\n",
       " 'iraq': 718,\n",
       " 'hour': 719,\n",
       " 'solution': 720,\n",
       " 'projects': 721,\n",
       " 'exactly': 722,\n",
       " 'essential': 723,\n",
       " 'letter': 724,\n",
       " 'respect': 725,\n",
       " 'bush': 726,\n",
       " 'continues': 727,\n",
       " 'either': 728,\n",
       " 'received': 729,\n",
       " 'isnt': 730,\n",
       " 'committees': 731,\n",
       " 'expansion': 732,\n",
       " 'decades': 733,\n",
       " 'whats': 734,\n",
       " 'woman': 735,\n",
       " 'relief': 736,\n",
       " 'bringing': 737,\n",
       " 'close': 738,\n",
       " 'foreign': 739,\n",
       " 'someone': 740,\n",
       " 'known': 741,\n",
       " 'longer': 742,\n",
       " 'responsible': 743,\n",
       " 'invest': 744,\n",
       " 'chance': 745,\n",
       " 'poor': 746,\n",
       " 'putting': 747,\n",
       " 'foundation': 748,\n",
       " 'parents': 749,\n",
       " 'hundreds': 750,\n",
       " 'passage': 751,\n",
       " 'extend': 752,\n",
       " 'due': 753,\n",
       " 'payment': 754,\n",
       " 'safe': 755,\n",
       " 'later': 756,\n",
       " 'product': 757,\n",
       " 'taxpayers': 758,\n",
       " 'town': 759,\n",
       " 'old': 760,\n",
       " 'wyoming': 761,\n",
       " 'capandtrade': 762,\n",
       " 'certain': 763,\n",
       " 'authority': 764,\n",
       " 'consume': 765,\n",
       " 'based': 766,\n",
       " 'study': 767,\n",
       " 'effective': 768,\n",
       " 'breast': 769,\n",
       " 'measure': 770,\n",
       " 'news': 771,\n",
       " 'moving': 772,\n",
       " 'period': 773,\n",
       " 'motion': 774,\n",
       " 'key': 775,\n",
       " 'seems': 776,\n",
       " 'lack': 777,\n",
       " 'goals': 778,\n",
       " 'tried': 779,\n",
       " 'common': 780,\n",
       " 'honor': 781,\n",
       " 'nursing': 782,\n",
       " 'despite': 783,\n",
       " 'september': 784,\n",
       " 'passing': 785,\n",
       " 'schip': 786,\n",
       " 'status': 787,\n",
       " 'oil': 788,\n",
       " 'poverty': 789,\n",
       " 'term': 790,\n",
       " 'clearly': 791,\n",
       " 'grow': 792,\n",
       " 'diabetes': 793,\n",
       " 'retirement': 794,\n",
       " 'transportation': 795,\n",
       " 'goal': 796,\n",
       " 'simple': 797,\n",
       " 'billions': 798,\n",
       " 'ideas': 799,\n",
       " 'building': 800,\n",
       " 'august': 801,\n",
       " 'competition': 802,\n",
       " 'trust': 803,\n",
       " 'recession': 804,\n",
       " 'management': 805,\n",
       " 'lowincome': 806,\n",
       " 'leading': 807,\n",
       " 'city': 808,\n",
       " 'leave': 809,\n",
       " 'behalf': 810,\n",
       " 'governments': 811,\n",
       " 'ive': 812,\n",
       " 'grants': 813,\n",
       " 'beginning': 814,\n",
       " 'reasons': 815,\n",
       " 'supporting': 816,\n",
       " 'diseases': 817,\n",
       " 'representative': 818,\n",
       " 'expensive': 819,\n",
       " 'employers': 820,\n",
       " 'pensions': 821,\n",
       " 'board': 822,\n",
       " 'ranking': 823,\n",
       " 'pelosi': 824,\n",
       " 'show': 825,\n",
       " 'finding': 826,\n",
       " 'turn': 827,\n",
       " 'dealing': 828,\n",
       " 'numberpage': 829,\n",
       " 'started': 830,\n",
       " 'effect': 831,\n",
       " 'womens': 832,\n",
       " 'tennessee': 833,\n",
       " 'alone': 834,\n",
       " 'encourage': 835,\n",
       " 'justice': 836,\n",
       " 'whose': 837,\n",
       " 'position': 838,\n",
       " 'addressing': 839,\n",
       " 'wellbeing': 840,\n",
       " 'legislative': 841,\n",
       " 'form': 842,\n",
       " 'related': 843,\n",
       " 'wont': 844,\n",
       " 'protecting': 845,\n",
       " 'groups': 846,\n",
       " 'unemployed': 847,\n",
       " 'promote': 848,\n",
       " 'likely': 849,\n",
       " 'open': 850,\n",
       " 'waste': 851,\n",
       " 'mentioned': 852,\n",
       " 'mandate': 853,\n",
       " 'fda': 854,\n",
       " 'regulations': 855,\n",
       " 'international': 856,\n",
       " 'tremendous': 857,\n",
       " 'signed': 858,\n",
       " 'south': 859,\n",
       " 'began': 860,\n",
       " 'universal': 861,\n",
       " 'professionals': 862,\n",
       " 'direction': 863,\n",
       " 'giving': 864,\n",
       " 'build': 865,\n",
       " 'serving': 866,\n",
       " 'regard': 867,\n",
       " 'preexisting': 868,\n",
       " 'troops': 869,\n",
       " 'director': 870,\n",
       " 'county': 871,\n",
       " 'perhaps': 872,\n",
       " 'reducing': 873,\n",
       " 'florida': 874,\n",
       " 'story': 875,\n",
       " 'answer': 876,\n",
       " 'price': 877,\n",
       " 'standards': 878,\n",
       " 'considered': 879,\n",
       " 'wants': 880,\n",
       " 'appropriate': 881,\n",
       " 'difference': 882,\n",
       " 'former': 883,\n",
       " 'pretty': 884,\n",
       " 'truly': 885,\n",
       " 'obviously': 886,\n",
       " 'career': 887,\n",
       " 'decade': 888,\n",
       " 'commend': 889,\n",
       " 'solutions': 890,\n",
       " 'indian': 891,\n",
       " 'involved': 892,\n",
       " 'introducing': 893,\n",
       " 'priority': 894,\n",
       " 'creates': 895,\n",
       " 'minority': 896,\n",
       " 'john': 897,\n",
       " 'ones': 898,\n",
       " 'physical': 899,\n",
       " 'sides': 900,\n",
       " 'primary': 901,\n",
       " 'allowed': 902,\n",
       " 'steps': 903,\n",
       " 'fully': 904,\n",
       " 'affect': 905,\n",
       " 'threat': 906,\n",
       " 'cobra': 907,\n",
       " 'asking': 908,\n",
       " 'proposals': 909,\n",
       " 'choose': 910,\n",
       " 'practice': 911,\n",
       " 'loss': 912,\n",
       " 'nutrition': 913,\n",
       " 'underlying': 914,\n",
       " 'commission': 915,\n",
       " 'cutting': 916,\n",
       " 'distinguished': 917,\n",
       " 'seeing': 918,\n",
       " 'estimated': 919,\n",
       " 'socalled': 920,\n",
       " 'agreement': 921,\n",
       " 'introduce': 922,\n",
       " 'enforcement': 923,\n",
       " 'requires': 924,\n",
       " 'consumer': 925,\n",
       " 'else': 926,\n",
       " 'tomorrow': 927,\n",
       " 'institutes': 928,\n",
       " 'closed': 929,\n",
       " 'voting': 930,\n",
       " 'balance': 931,\n",
       " 'north': 932,\n",
       " 'cases': 933,\n",
       " 'specifically': 934,\n",
       " 'forced': 935,\n",
       " 'capital': 936,\n",
       " 'burden': 937,\n",
       " 'focused': 938,\n",
       " 'banks': 939,\n",
       " 'using': 940,\n",
       " 'required': 941,\n",
       " 'worse': 942,\n",
       " 'five': 943,\n",
       " 'evening': 944,\n",
       " 'alternative': 945,\n",
       " 'direct': 946,\n",
       " 'generation': 947,\n",
       " 'running': 948,\n",
       " 'reauthorization': 949,\n",
       " 'reality': 950,\n",
       " 'meeting': 951,\n",
       " 'somebody': 952,\n",
       " 'fear': 953,\n",
       " 'welfare': 954,\n",
       " 'educational': 955,\n",
       " 'condition': 956,\n",
       " 'stay': 957,\n",
       " 'annual': 958,\n",
       " 'smoking': 959,\n",
       " 'following': 960,\n",
       " 'reserve': 961,\n",
       " 'achieve': 962,\n",
       " 'reconciliation': 963,\n",
       " 'section': 964,\n",
       " 'agenda': 965,\n",
       " 'represents': 966,\n",
       " 'workforce': 967,\n",
       " 'return': 968,\n",
       " 'led': 969,\n",
       " 'supported': 970,\n",
       " 'effects': 971,\n",
       " 'century': 972,\n",
       " 'success': 973,\n",
       " 'society': 974,\n",
       " 'employment': 975,\n",
       " 'gets': 976,\n",
       " 'task': 977,\n",
       " 'third': 978,\n",
       " 'oppose': 979,\n",
       " 'fraud': 980,\n",
       " 'wait': 981,\n",
       " 'various': 982,\n",
       " 'purchase': 983,\n",
       " 'progress': 984,\n",
       " 'room': 985,\n",
       " 'massachusetts': 986,\n",
       " 'consideration': 987,\n",
       " 'solve': 988,\n",
       " 'happens': 989,\n",
       " 'pointed': 990,\n",
       " 'fundamental': 991,\n",
       " 'reid': 992,\n",
       " 'points': 993,\n",
       " 'interesting': 994,\n",
       " 'raised': 995,\n",
       " 'prices': 996,\n",
       " 'covered': 997,\n",
       " 'promise': 998,\n",
       " 'tough': 999,\n",
       " 'allows': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23838"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer.texts_to_sequences(speaker_speeches.get_group(speaker_keys[0]).speech.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[334,\n",
       "  7805,\n",
       "  7662,\n",
       "  3065,\n",
       "  5281,\n",
       "  466,\n",
       "  426,\n",
       "  1488,\n",
       "  548,\n",
       "  232,\n",
       "  14,\n",
       "  2719,\n",
       "  479,\n",
       "  15710,\n",
       "  5957,\n",
       "  606,\n",
       "  4776,\n",
       "  625,\n",
       "  7939,\n",
       "  4575,\n",
       "  334,\n",
       "  888,\n",
       "  606,\n",
       "  15711,\n",
       "  276,\n",
       "  1,\n",
       "  276,\n",
       "  11232,\n",
       "  5161,\n",
       "  259,\n",
       "  638,\n",
       "  1015,\n",
       "  1425,\n",
       "  961,\n",
       "  293,\n",
       "  2,\n",
       "  5492,\n",
       "  21,\n",
       "  6522,\n",
       "  158,\n",
       "  741,\n",
       "  7023,\n",
       "  534,\n",
       "  15712,\n",
       "  11233,\n",
       "  5492,\n",
       "  692,\n",
       "  186,\n",
       "  3717,\n",
       "  7026],\n",
       " [125,\n",
       "  153,\n",
       "  14,\n",
       "  981,\n",
       "  103,\n",
       "  73,\n",
       "  30,\n",
       "  2218,\n",
       "  5036,\n",
       "  4465,\n",
       "  223,\n",
       "  99,\n",
       "  273,\n",
       "  20,\n",
       "  694,\n",
       "  549,\n",
       "  557,\n",
       "  273,\n",
       "  45,\n",
       "  30,\n",
       "  577,\n",
       "  2814,\n",
       "  77,\n",
       "  904,\n",
       "  2093,\n",
       "  1,\n",
       "  3,\n",
       "  461,\n",
       "  99,\n",
       "  16,\n",
       "  266,\n",
       "  624,\n",
       "  84,\n",
       "  632,\n",
       "  1189,\n",
       "  1962,\n",
       "  1524,\n",
       "  2,\n",
       "  143,\n",
       "  1757,\n",
       "  59,\n",
       "  67,\n",
       "  1820,\n",
       "  85,\n",
       "  38,\n",
       "  549,\n",
       "  30,\n",
       "  577,\n",
       "  2926,\n",
       "  259],\n",
       " [89,\n",
       "  8,\n",
       "  266,\n",
       "  616,\n",
       "  19947,\n",
       "  275,\n",
       "  226,\n",
       "  1892,\n",
       "  5457,\n",
       "  332,\n",
       "  208,\n",
       "  2229,\n",
       "  3623,\n",
       "  810,\n",
       "  63,\n",
       "  94,\n",
       "  142,\n",
       "  1892,\n",
       "  142,\n",
       "  22,\n",
       "  18,\n",
       "  11,\n",
       "  1,\n",
       "  3,\n",
       "  34,\n",
       "  20,\n",
       "  293,\n",
       "  375,\n",
       "  63,\n",
       "  94,\n",
       "  160,\n",
       "  25,\n",
       "  39,\n",
       "  974,\n",
       "  3,\n",
       "  116,\n",
       "  706,\n",
       "  31,\n",
       "  3,\n",
       "  1,\n",
       "  9,\n",
       "  53,\n",
       "  905,\n",
       "  94,\n",
       "  10,\n",
       "  2077,\n",
       "  30],\n",
       " [84,\n",
       "  68,\n",
       "  1482,\n",
       "  30,\n",
       "  1699,\n",
       "  938,\n",
       "  724,\n",
       "  4916,\n",
       "  1264,\n",
       "  63,\n",
       "  94,\n",
       "  23,\n",
       "  538,\n",
       "  160,\n",
       "  39,\n",
       "  274,\n",
       "  84,\n",
       "  68,\n",
       "  1482,\n",
       "  724,\n",
       "  30,\n",
       "  1699,\n",
       "  27,\n",
       "  990,\n",
       "  235,\n",
       "  1,\n",
       "  3,\n",
       "  598,\n",
       "  255,\n",
       "  1268,\n",
       "  2071,\n",
       "  702,\n",
       "  1819,\n",
       "  95,\n",
       "  2378,\n",
       "  98,\n",
       "  30,\n",
       "  3086,\n",
       "  3131,\n",
       "  549,\n",
       "  3415,\n",
       "  198,\n",
       "  274,\n",
       "  84,\n",
       "  68,\n",
       "  3295,\n",
       "  62,\n",
       "  177,\n",
       "  54,\n",
       "  2417],\n",
       " [6,\n",
       "  8,\n",
       "  80,\n",
       "  16,\n",
       "  889,\n",
       "  148,\n",
       "  58,\n",
       "  67,\n",
       "  1,\n",
       "  56,\n",
       "  351,\n",
       "  821,\n",
       "  148,\n",
       "  58,\n",
       "  38,\n",
       "  47,\n",
       "  1338,\n",
       "  1381,\n",
       "  32,\n",
       "  2,\n",
       "  636,\n",
       "  67,\n",
       "  3223,\n",
       "  1841,\n",
       "  47,\n",
       "  1338,\n",
       "  81,\n",
       "  958,\n",
       "  2004,\n",
       "  2238,\n",
       "  33,\n",
       "  462,\n",
       "  11752]]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = WINDOW_DEFAULT + 1\n",
    "x_train_padded = pad_sequences(x_train, maxlen=max_len, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  334,  7805,  7662,  3065,  5281,   466,   426,  1488,   548,\n",
       "          232,    14,  2719,   479, 15710,  5957,   606,  4776,   625,\n",
       "         7939,  4575,   334,   888,   606, 15711,   276,     1,   276,\n",
       "        11232,  5161,   259,   638,  1015,  1425,   961,   293,     2,\n",
       "         5492,    21,  6522,   158,   741,  7023,   534, 15712, 11233,\n",
       "         5492,   692,   186,  3717,  7026,     0],\n",
       "       [  125,   153,    14,   981,   103,    73,    30,  2218,  5036,\n",
       "         4465,   223,    99,   273,    20,   694,   549,   557,   273,\n",
       "           45,    30,   577,  2814,    77,   904,  2093,     1,     3,\n",
       "          461,    99,    16,   266,   624,    84,   632,  1189,  1962,\n",
       "         1524,     2,   143,  1757,    59,    67,  1820,    85,    38,\n",
       "          549,    30,   577,  2926,   259,     0],\n",
       "       [   89,     8,   266,   616, 19947,   275,   226,  1892,  5457,\n",
       "          332,   208,  2229,  3623,   810,    63,    94,   142,  1892,\n",
       "          142,    22,    18,    11,     1,     3,    34,    20,   293,\n",
       "          375,    63,    94,   160,    25,    39,   974,     3,   116,\n",
       "          706,    31,     3,     1,     9,    53,   905,    94,    10,\n",
       "         2077,    30,     0,     0,     0,     0],\n",
       "       [   84,    68,  1482,    30,  1699,   938,   724,  4916,  1264,\n",
       "           63,    94,    23,   538,   160,    39,   274,    84,    68,\n",
       "         1482,   724,    30,  1699,    27,   990,   235,     1,     3,\n",
       "          598,   255,  1268,  2071,   702,  1819,    95,  2378,    98,\n",
       "           30,  3086,  3131,   549,  3415,   198,   274,    84,    68,\n",
       "         3295,    62,   177,    54,  2417,     0],\n",
       "       [    6,     8,    80,    16,   889,   148,    58,    67,     1,\n",
       "           56,   351,   821,   148,    58,    38,    47,  1338,  1381,\n",
       "           32,     2,   636,    67,  3223,  1841,    47,  1338,    81,\n",
       "          958,  2004,  2238,    33,   462, 11752,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that the sentences need to be in integer-tokenized form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Iyyer et el.\n",
    "\n",
    "\"Each input to the RMN is a tuple that contains identifiers for a book and two character, as well as the spans corresponding to their relationship: $(b, c_1, c_2, S_{c_1,c_2})$. Given one such input, our objective istoreconstruct S_(c1,c2) using alinear combination of relationship descriptors from R as shown in Figure 2; we now describe this process formally.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Needs for Baseline goal\n",
    "\n",
    "Let...\n",
    "* $s_{v_t}$ be the $t_{th}$ span of text in the span set $S_{c_1,c_2}$\n",
    "* $v_{s_t}$ be the vector that results from taking the element-wise average of the word vectors in $s_{v_t}$\n",
    "* $d$ be the dimension of the embedding\n",
    "* $k$ be the number of decsriptors\n",
    "\n",
    "\n",
    "Compute Sequence: Given $s_{v_t}$, do the following steps:\n",
    "1. compute avg speech vector, $v_{s_t}$,\n",
    "    * $v_{s_t} \\in \\mathbb{R}^{d}$\n",
    "2. compute hidden state with Relu activation: \n",
    "    * $h_t =  relu \\space (W_h \\cdot v_{s_t})$\n",
    "    * $W_h \\in \\mathbb{R}^{d \\times d}$ \n",
    "    * $h_t \\in  \\mathbb{R}^{d}$\n",
    "3. get distribution over topics using another hidden layer: \n",
    "    * $d_t = softmax \\space (W_d \\cdot h_t)$\n",
    "    * $W_d \\in  \\mathbb{R}^{k \\times d}$\n",
    "    * $d_t \\in  \\mathbb{R}^{k}$\n",
    "    * $d_{t,i} \\in (0,1) \\space \\forall i$ \n",
    "4. recompose original sentence using the distribution over descriptors and the descriptor matrix:\n",
    "    * $r_t = R^Td_t$\n",
    "    * $R^T \\in \\mathbb{R}^{d \\times k}$\n",
    "    * $r_t \\in \\mathbb{R}^{d}$\n",
    "5. score distance between $r_t$ and $v_{s_t}$\n",
    "    * $distance = dist(r_t, v_{s_t})$\n",
    "    \n",
    "    \n",
    "#### Notes on implementing it with keras\n",
    "Every step that uses a matrix multiplication above can be implemented in keras using a dense layer, formatted like this:\n",
    "* `h = keras.layers.Dense(units = a, input_shape = (b, ), activation= \"the_activation\")(prev_layer)`\n",
    "    * This will make the dense layer use a weight matrix $W \\in \\mathbb{R}^{a \\times b}$, and activation \"`the_activation`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Embedding, Dense, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100\n",
    "k = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordids = keras.layers.Input(shape=(max_len,))\n",
    "\n",
    "# Embed the wordids.\n",
    "e = keras.layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=d, \n",
    "                           input_length=max_len)(wordids)\n",
    "\n",
    "# Take elementwise average over vectors\n",
    "a = keras.layers.Lambda(lambda x: keras.backend.mean(x, axis=1))(e)\n",
    "\n",
    "# dense layer\n",
    "ht = keras.layers.Dense(units = d, input_shape = (d, ), activation = \"relu\")(a)\n",
    "\n",
    "# dense layer with softmax activation, (where previous states will eventually be inserted) \n",
    "dt = keras.layers.Dense(units = k, input_shape = (d, ), activation = \"softmax\")(ht)\n",
    "\n",
    "# reconstruction layer\n",
    "rt = keras.layers.Dense(units = d, input_shape = (k, ), activation = \"linear\")(dt)\n",
    "\n",
    "# rt = keras.layers.Dense(units = d, input_shape = (k, ), activation = \"linear\")(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_34/BiasAdd:0\", shape=(?, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 51, 100)           2383800   \n",
      "_________________________________________________________________\n",
      "lambda_9 (Lambda)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 100)               2100      \n",
      "=================================================================\n",
      "Total params: 2,398,020\n",
      "Trainable params: 2,398,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model = keras.Model(inputs=wordids, outputs=rt)\n",
    "model.compile(optimizer = 'adam', loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_34 to have shape (100,) but got array with shape (51,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-1ec490db0998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_34 to have shape (100,) but got array with shape (51,)"
     ]
    }
   ],
   "source": [
    "model.fit(x=x_train_padded, y=x_train_padded, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fd9dc31af90>\n",
      "==================================================\n",
      "input shape (None, 51)\n",
      "output shape (None, 51)\n",
      "<keras.layers.embeddings.Embedding object at 0x7fd9dc31add0>\n",
      "==================================================\n",
      "input shape (None, 51)\n",
      "output shape (None, 51, 100)\n",
      "<keras.layers.core.Lambda object at 0x7fd9dc208d90>\n",
      "==================================================\n",
      "input shape (None, 51, 100)\n",
      "output shape (None, 100)\n",
      "<keras.layers.core.Dense object at 0x7fd9dc31acd0>\n",
      "==================================================\n",
      "input shape (None, 100)\n",
      "output shape (None, 100)\n",
      "<keras.layers.core.Dense object at 0x7fd9dc31ad50>\n",
      "==================================================\n",
      "input shape (None, 100)\n",
      "output shape (None, 20)\n",
      "<keras.layers.core.Dense object at 0x7fd9dc371a10>\n",
      "==================================================\n",
      "input shape (None, 20)\n",
      "output shape (None, 100)\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers:\n",
    "    print(l)\n",
    "    print(50*\"=\")\n",
    "    print(\"input shape\", l.input_shape)\n",
    "    print(\"output shape\", l.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer flatten_2: expected min_ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-fd598af1f156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected min_ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer flatten_2: expected min_ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(4,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
