{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMN Training\n",
    "\n",
    "Training an RMN on sessions 105 - 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../../scripts/assembly/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from document import *\n",
    "from subject import subject_keywords\n",
    "from constant import DOC_PROPER_PATH, DOCUMENT, SESSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = load_documents([111], DOC_PROPER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speakerid</th>\n",
       "      <th>lastname</th>\n",
       "      <th>firstname</th>\n",
       "      <th>chamber</th>\n",
       "      <th>state</th>\n",
       "      <th>gender</th>\n",
       "      <th>party</th>\n",
       "      <th>document</th>\n",
       "      <th>subject</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>111117170</td>\n",
       "      <td>TOWNS</td>\n",
       "      <td>EDOLPHUS</td>\n",
       "      <td>H</td>\n",
       "      <td>NY</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>wouldnt we ban it i know the from has said may...</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>111119891</td>\n",
       "      <td>ISAKSON</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>S</td>\n",
       "      <td>GA</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>acts of terrorism we took the blind sheikthe f...</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>111117461</td>\n",
       "      <td>ROCKEFELLER</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>S</td>\n",
       "      <td>WV</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>buddy program and has been a lunch buddy for  ...</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>111118860</td>\n",
       "      <td>CARTER</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>H</td>\n",
       "      <td>TX</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>assessment of the zero budgetary impact of thi...</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>111118701</td>\n",
       "      <td>BOXER</td>\n",
       "      <td>BARBARA</td>\n",
       "      <td>S</td>\n",
       "      <td>CA</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>school curriculum and the challenges they see ...</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speakerid     lastname firstname chamber state gender party  \\\n",
       "0  111117170        TOWNS  EDOLPHUS       H    NY      M     D   \n",
       "1  111119891      ISAKSON      JOHN       S    GA      M     R   \n",
       "2  111117461  ROCKEFELLER      JOHN       S    WV      M     D   \n",
       "3  111118860       CARTER      JOHN       H    TX      M     R   \n",
       "4  111118701        BOXER   BARBARA       S    CA      F     D   \n",
       "\n",
       "                                            document  subject session  \n",
       "0  wouldnt we ban it i know the from has said may...  alcohol     111  \n",
       "1  acts of terrorism we took the blind sheikthe f...  alcohol     111  \n",
       "2  buddy program and has been a lunch buddy for  ...  alcohol     111  \n",
       "3  assessment of the zero budgetary impact of thi...  alcohol     111  \n",
       "4  school curriculum and the challenges they see ...  alcohol     111  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speakerid    object\n",
       "lastname     object\n",
       "firstname    object\n",
       "chamber      object\n",
       "state        object\n",
       "gender       object\n",
       "party        object\n",
       "document     object\n",
       "subject      object\n",
       "session      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166133, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### run several times\n",
    "os.chdir(\"../modeling\")\n",
    "from token_mapping import *\n",
    "from embeddings import *\n",
    "from helper import load_pickled_object\n",
    "from rmn import RMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    " 'speakerid',\n",
    " 'chamber',\n",
    " 'state',\n",
    " 'gender',\n",
    " 'party',\n",
    " 'session',\n",
    " 'subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tokenizer and metadata dicts\n",
    "tokenizer_dict = build_tokenizer_dict(docs_df, max_span_len=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tokenizer', 'tokenize_pad', 'word_index', 'max_span_length'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['speakerid', 'chamber', 'state', 'gender', 'party', 'session', 'subject'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_dict = build_metadata_dict(docs_df, feature_columns)\n",
    "metadata_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings\n",
    "embedding_file = \"/home/rocassius/gen-data/tools/embbedding_index_50d\"\n",
    "embeddings_index = load_pickled_object(embedding_file)\n",
    "embeddings_matrix = build_embedding_matrix(tokenizer_dict['word_index'], embeddings_index).astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94696, 50)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import Regularizer\n",
    "\n",
    "class Orthogonality(Regularizer):\n",
    "    \"\"\"Regularizer for discouraging non-orthogonal components.\n",
    "    \n",
    "    # Arguments\n",
    "        lamb: Float; regularization penalty weight\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lamb = 1.):\n",
    "        self.lamb = lamb\n",
    "\n",
    "    def __call__(self, R):\n",
    "        RRT = K.dot(R, K.transpose(R))\n",
    "        I = K.eye(int(RRT.shape[0]))\n",
    "        penalty = self.lamb * K.sqrt(K.sum(K.square(RRT - I)))\n",
    "        \n",
    "        return penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================#\n",
    "#=*= RMN Module =*=#\n",
    "#==================#\n",
    "\n",
    "# RMN Class for training Relationship Modeling Networks \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Embedding, Dense, Lambda, Input, Masking, Reshape\n",
    "from tensorflow.keras.models import load_model, model_from_json\n",
    "\n",
    "from helper import pickle_object, load_pickled_object\n",
    "from vector_math import find_nn_cos\n",
    "\n",
    "# constants\n",
    "MAX_SPAN_LENGTH = 50\n",
    "NUM_TOPICS = 20\n",
    "LAMBDA = 5.0\n",
    "\n",
    "OPTIMIZER = 'adam'\n",
    "BATCH_SIZE = 50\n",
    "EPOCHS = 5\n",
    "\n",
    "RMN_TAG = \"rmn_%s\"\n",
    "MODEL = \"model.h5\"\n",
    "ARCH = \"architecture\"\n",
    "ATTR = \"attributes\"\n",
    "\n",
    "\n",
    "class RMN(object):\n",
    "    \"\"\"\n",
    "    Class for constructing a Relationship Modeling Network\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # model parameters\n",
    "        self.num_topics = NUM_TOPICS\n",
    "        self.lamb = LAMBDA\n",
    "        \n",
    "        # model attrbiutes\n",
    "        self.embedding_matrix = None\n",
    "        self.tokenizer_dict = None\n",
    "        self.metadata_dict = None\n",
    "        \n",
    "        # models \n",
    "        self.model = None\n",
    "        self.topic_model = None\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def embedding_dim(self):\n",
    "        return self.embedding_matrix.shape[1]\n",
    "    \n",
    "    \n",
    "    def model_loss(self):\n",
    "        \"\"\"Hinge loss function.\n",
    "        \"\"\"\n",
    "        def custom_loss(y_true, y_pred):\n",
    "            # hinge_loss\n",
    "            y_true_normalized = K.l2_normalize(y_true, axis=-1)\n",
    "            y_pred_normalized = K.l2_normalize(y_pred, axis=-1)\n",
    "            dot_product = K.sum(y_true_normalized * y_pred_normalized, axis=-1)\n",
    "            hinge_loss = K.mean(K.maximum(0., 1. - dot_product))\n",
    "\n",
    "            return hinge_loss \n",
    "\n",
    "        return custom_loss\n",
    "    \n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"Connstruct the RMN model architecture\n",
    "        \"\"\"\n",
    "        # document span input\n",
    "        vt = Input(shape=(self.embedding_dim, ), name='Span.Input')\n",
    "    \n",
    "        input_layers = [vt]\n",
    "        embedding_layers = [vt]\n",
    "        \n",
    "        for col in self.metadata_dict.keys():\n",
    "            \n",
    "            input_layer = Input(shape=(1,), name= col + '.Input')\n",
    "            \n",
    "            # embedding layer for col\n",
    "            embedding_init = Embedding(\n",
    "                input_dim = self.metadata_dict[col]['input_dim'] + 1, \n",
    "                output_dim = self.embedding_dim,\n",
    "                input_length = 1)(input_layer)\n",
    "            \n",
    "            # reshape\n",
    "            embedding_layer = Reshape((self.embedding_dim, ), name=col + '.Embed.Layer')(embedding_init)\n",
    "            \n",
    "            input_layers.append(input_layer)\n",
    "            embedding_layers.append(embedding_layer)\n",
    "\n",
    "        # concat speaker metadata embeddings\n",
    "        _ht = tf.keras.layers.Concatenate(axis=1, name = 'Concat.Layer')(embedding_layers)\n",
    "\n",
    "        # dense layer\n",
    "        ht = Dense(units = self.embedding_dim, \n",
    "                   input_shape = (_ht.shape[1], ), \n",
    "                   activation = \"relu\", name = \"Wh\")(_ht)\n",
    "\n",
    "        # dense layer with softmax activation, (where previous states will eventually be inserted) \n",
    "        dt = Dense(units = self.num_topics, \n",
    "                   input_shape = (self.embedding_dim, ), \n",
    "                   activation = \"softmax\", name = \"Wd\")(ht)\n",
    "\n",
    "        # reconstruction layer\n",
    "        rt = Dense(units = self.embedding_dim,\n",
    "                   input_shape = (self.num_topics, ),\n",
    "                   activation = \"linear\",\n",
    "                   kernel_regularizer = Orthogonality(self.lamb),\n",
    "                   name = \"R\")(dt)\n",
    "\n",
    "        # compile\n",
    "        model = tf.keras.Model(inputs=input_layers, outputs=rt)\n",
    "        model.compile(optimizer = OPTIMIZER, loss = self.model_loss())\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "    \n",
    "    def build_topic_model(self, topic_layer = \"Wd\"):\n",
    "        \"\"\"Contruct model whose output is the topic distribution layer\n",
    "        \"\"\"\n",
    "        topic_model = tf.keras.Model(\n",
    "            inputs = self.model.input,\n",
    "            outputs = self.model.get_layer(topic_layer).output)\n",
    "        \n",
    "        self.topic_model = topic_model\n",
    "    \n",
    "    def prep_y(self, y):\n",
    "        \"\"\"Returns the average of the vectors in each span of text\n",
    "        \"\"\"\n",
    "        padded_spans = self.tokenizer_dict['tokenize_pad'](y)\n",
    "        vector_spans = self.embedding_matrix[padded_spans].mean(axis=1)\n",
    "        \n",
    "        return vector_spans\n",
    "    \n",
    "    \n",
    "    def prep_metadata(self, df):\n",
    "        \"\"\"Preps metadata for training or prediction\n",
    "        \"\"\"\n",
    "        metadata_ids = [np.array(self.metadata_dict[col]['tokenize'](df[col]))\n",
    "                        for col in self.metadata_dict.keys()]\n",
    "\n",
    "        return metadata_ids\n",
    "        \n",
    "    \n",
    "    def prep_inputs(self, df):\n",
    "        \"\"\"Preps metadata for training or prediction\n",
    "        \"\"\"\n",
    "        vector_spans = self.prep_y(df['document'])\n",
    "        metadata_ids = self.prep_metadata(df)\n",
    "        inputs = [vector_spans] + metadata_ids\n",
    "        \n",
    "        return inputs\n",
    "    \n",
    "    \n",
    "    def predict_topics(self, df):\n",
    "        \"\"\"Predicts the topic distributions for a df\n",
    "        \"\"\"\n",
    "        \n",
    "        # ensure the topic model has been built\n",
    "        if self.topic_model is None:\n",
    "            self.build_topic_model()\n",
    "            \n",
    "        topic_preds = self.topic_model.predict(x=self.prep_inputs(df))\n",
    "        \n",
    "        return topic_preds\n",
    "    \n",
    "    \n",
    "    def fit(self, df, batch_size = BATCH_SIZE, epochs = EPOCHS):\n",
    "        \n",
    "        inputs = self.prep_inputs(df)\n",
    "        y_true = self.prep_y(df['document'])\n",
    "        \n",
    "        self.model.fit(x = inputs, \n",
    "                       y = y_true, \n",
    "                       batch_size = batch_size, \n",
    "                       epochs = epochs)\n",
    "\n",
    "    \n",
    "    def save_rmn(self, name, save_path):\n",
    "        \"\"\"\n",
    "        Save the model's weights, architecture and attributes\n",
    "        \"\"\"\n",
    "        \n",
    "        # assemble attribute dictionary\n",
    "        attribute_dict = {\n",
    "            'num_topics': self.num_topics,\n",
    "            'emedding_matrix': self.embedding_matrix,\n",
    "            'tokenizer_dict': self.tokenizer_dict,\n",
    "            'metadata_dict': self.metadata_dict}\n",
    "        \n",
    "        # make directory for model\n",
    "        model_path = os.path.join(save_path, RMN_TAG % name)\n",
    "        os.mkdir(model_path)\n",
    "        \n",
    "        # save model weights\n",
    "        self.model.save(os.path.join(model_path, MODEL))\n",
    "        \n",
    "        # save model architecture\n",
    "        pickle_object(self.model.to_json(), os.path.join(model_path, ARCH))\n",
    "        \n",
    "        # save model attributes\n",
    "        pickle_object(attribute_dict, os.path.join(model_path, ATTR))\n",
    "        \n",
    "        \n",
    "    def load_rmn(self, name, save_path):\n",
    "        \"\"\"\n",
    "        Load the model, weights, architecture and attributes from a saved model\n",
    "        \"\"\"\n",
    "        \n",
    "        # make directory for model\n",
    "        model_path = os.path.join(save_path, RMN_TAG % name)\n",
    "        \n",
    "        # Load architecture and weights\n",
    "        self.model = model_from_json(load_pickled_object(os.path.join(model_path, ARCH)))\n",
    "        self.model.load_weights(os.path.join(model_path, MODEL))\n",
    "        \n",
    "        # load attributes\n",
    "        attributes_dict = load_pickled_object(os.path.join(model_path, ATTR))\n",
    "        \n",
    "        # update attributes\n",
    "        self.num_topics = attributes_dict['num_topics']\n",
    "        self.embedding_matrix = attributes_dict['emedding_matrix']\n",
    "        self.tokenizer_dict = attributes_dict['tokenizer_dict']\n",
    "        self.metadata_dict = attributes_dict['metadata_dict']\n",
    "       \n",
    "    \n",
    "    def inspect_topics(self, k_neighbors=10):\n",
    "        \"\"\"\n",
    "        Ouput the nearest neighbors of every topic vector in\n",
    "        the model's topic layer\n",
    "        \"\"\"\n",
    "    \n",
    "        # get embedding matrix, dim = [num_words, embedding_dim]\n",
    "        E = self.embedding_matrix\n",
    "        \n",
    "        # get topic matrix, dim = [num_topics, embedding_dim]\n",
    "        Wd = self.model.get_layer('Wd').get_weights()[0].T\n",
    "        \n",
    "        for i in range(Wd.shape[0]):\n",
    "            \n",
    "            neighbors, sim = find_nn_cos(Wd[i], E, k_neighbors)\n",
    "            words = [self.tokenizer_dict['tokenizer'].index_word[v] for v in neighbors]\n",
    "            \n",
    "            print(20*\"=\" +\"\\n\")\n",
    "            print(\"Topic\", i)\n",
    "            print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmn = RMN()\n",
    "rmn.embedding_matrix = embeddings_matrix\n",
    "rmn.tokenizer_dict = tokenizer_dict\n",
    "rmn.metadata_dict = metadata_dict\n",
    "# num descriptors = 4 times number of subjects\n",
    "rmn.num_topics = 100\n",
    "rmn.lamb = 1.\n",
    "rmn.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = rmn.prep_inputs(docs_df)\n",
    "# y = inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166133, 50)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166133 samples\n",
      "Epoch 1/10\n",
      "166133/166133 [==============================] - 4s 21us/sample - loss: 7.0718\n",
      "Epoch 2/10\n",
      "166133/166133 [==============================] - 4s 21us/sample - loss: 7.0716\n",
      "Epoch 3/10\n",
      "166133/166133 [==============================] - 3s 21us/sample - loss: 7.0716\n",
      "Epoch 4/10\n",
      "166133/166133 [==============================] - 3s 21us/sample - loss: 7.0716\n",
      "Epoch 5/10\n",
      "166133/166133 [==============================] - 3s 20us/sample - loss: 7.0715\n",
      "Epoch 6/10\n",
      "166133/166133 [==============================] - 3s 21us/sample - loss: 7.0714\n",
      "Epoch 7/10\n",
      "166133/166133 [==============================] - 3s 21us/sample - loss: 7.0714\n",
      "Epoch 8/10\n",
      "166133/166133 [==============================] - 3s 21us/sample - loss: 7.0713\n",
      "Epoch 9/10\n",
      "166133/166133 [==============================] - 3s 21us/sample - loss: 7.0713\n",
      "Epoch 10/10\n",
      "166133/166133 [==============================] - 4s 21us/sample - loss: 7.0713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda49f5c890>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmn.model.fit(x=inputs, \n",
    "              y=y, \n",
    "              epochs = 10, \n",
    "              batch_size = 200, \n",
    "              use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "\n",
      "Topic 0\n",
      "['amnesty', 'opm', 'zimbabwean', 'repatriate', 'zimbabwe']\n",
      "====================\n",
      "\n",
      "Topic 1\n",
      "['excerpts', 'speech', 'eulogy', 'fanfare', 'editorial']\n",
      "====================\n",
      "\n",
      "Topic 2\n",
      "['opennet', 'sentinels', 'blacklists', 'nro', 'conspirator']\n",
      "====================\n",
      "\n",
      "Topic 3\n",
      "['tl', 'tor', 'defines', 'incidence', 'punctuation']\n",
      "====================\n",
      "\n",
      "Topic 4\n",
      "['dams', 'moratorium', 'reef', 'chernobyl', 'cod']\n",
      "====================\n",
      "\n",
      "Topic 5\n",
      "['avionics', 'shigeru', 'atypical', 'bergquist', 'lute']\n",
      "====================\n",
      "\n",
      "Topic 6\n",
      "['thetford', 'dredge', 'plating', 'berms', 'sealer']\n",
      "====================\n",
      "\n",
      "Topic 7\n",
      "['een', 'planeta', 'zine', 'eady', 'pres']\n",
      "====================\n",
      "\n",
      "Topic 8\n",
      "['disgruntled', 'sinhalese', 'beleaguered', 'minority', 'suing']\n",
      "====================\n",
      "\n",
      "Topic 9\n",
      "['gut', 'nagging', 'arthritic', 'gnawing', 'eats']\n",
      "====================\n",
      "\n",
      "Topic 10\n",
      "['hondas', 'vanlandingham', 'musket', 'slipshod', 'taxiing']\n",
      "====================\n",
      "\n",
      "Topic 11\n",
      "['roundtables', 'brazile', 'greentech', 'dovetailed', 'marni']\n",
      "====================\n",
      "\n",
      "Topic 12\n",
      "['middleclass', 'dignitary', 'noemi', 'biracial', 'officeholder']\n",
      "====================\n",
      "\n",
      "Topic 13\n",
      "['perpetrate', 'misbranding', 'meritless', 'lilo', 'messrs']\n",
      "====================\n",
      "\n",
      "Topic 14\n",
      "['reynosa', 'salina', 'walder', 'hite', 'mcallen']\n",
      "====================\n",
      "\n",
      "Topic 15\n",
      "['lettuce', 'romaine', 'ripe', 'mashed', 'onions']\n",
      "====================\n",
      "\n",
      "Topic 16\n",
      "['reif', 'deutche', 'tavis', 'klingenstein', 'hln']\n",
      "====================\n",
      "\n",
      "Topic 17\n",
      "['allergies', 'beets', 'fester', 'metastasize', 'pests']\n",
      "====================\n",
      "\n",
      "Topic 18\n",
      "['jan', 'lars', 'albrecht', 'nielsen', 'seymour']\n",
      "====================\n",
      "\n",
      "Topic 19\n",
      "['p', 'ar', 'keppel', 'croft', 'infinite']\n",
      "====================\n",
      "\n",
      "Topic 20\n",
      "['reclamation', 'hydrocarbon', 'federally', 'conservation', 'preservation']\n",
      "====================\n",
      "\n",
      "Topic 21\n",
      "['equestrian', 'auschwitz', 'treblinka', 'gagarin', 'sachsenhausen']\n",
      "====================\n",
      "\n",
      "Topic 22\n",
      "['siring', 'hungered', 'partakes', 'medaled', 'chidren']\n",
      "====================\n",
      "\n",
      "Topic 23\n",
      "['landsbergis', 'unshackle', 'devante', 'orval', 'wampanoags']\n",
      "====================\n",
      "\n",
      "Topic 24\n",
      "['archer', 'daniels', 'melson', 'macdiarmid', 'underwriter']\n",
      "====================\n",
      "\n",
      "Topic 25\n",
      "['drive', 'stops', 'carries', 'stopping', 'free']\n",
      "====================\n",
      "\n",
      "Topic 26\n",
      "['nonresident', 'diplomate', 'thespian', 'rotarian', 'delva']\n",
      "====================\n",
      "\n",
      "Topic 27\n",
      "['crawshaw', 'fixating', 'bunner', 'legislates', 'editorializing']\n",
      "====================\n",
      "\n",
      "Topic 28\n",
      "['homeruns', 'talkabout', 'laredos', 'encyclopedias', 'arounds']\n",
      "====================\n",
      "\n",
      "Topic 29\n",
      "['planners', 'manned', 'attracting', 'scaled', 'accommodated']\n",
      "====================\n",
      "\n",
      "Topic 30\n",
      "['dines', 'sneaks', 'buttonholed', 'zazi', 'blagojevich']\n",
      "====================\n",
      "\n",
      "Topic 31\n",
      "['aggregator', 'semiannual', 'lotto', 'boskin', 'preview']\n",
      "====================\n",
      "\n",
      "Topic 32\n",
      "['confederacy', 'divides', 'divide', 'splits', 'dividing']\n",
      "====================\n",
      "\n",
      "Topic 33\n",
      "['kills', 'blaze', 'injures', 'explosion', 'mine']\n",
      "====================\n",
      "\n",
      "Topic 34\n",
      "['voiceover', 'contralto', 'uncredited', 'weigel', 'spitfire']\n",
      "====================\n",
      "\n",
      "Topic 35\n",
      "['strange', 'smoke', 'light', 'blowing', 'guy']\n",
      "====================\n",
      "\n",
      "Topic 36\n",
      "['counterpoint', 'propulsive', 'multilayered', 'cacophonous', 'sextet']\n",
      "====================\n",
      "\n",
      "Topic 37\n",
      "['detonations', 'fab', 'nickles', 'riegle', 'nabors']\n",
      "====================\n",
      "\n",
      "Topic 38\n",
      "['usc', 'quarterback', 'eligibility', 'assessing', 'tebow']\n",
      "====================\n",
      "\n",
      "Topic 39\n",
      "['proclivities', 'listers', 'psychopath', 'julianna', 'indiscretions']\n",
      "====================\n",
      "\n",
      "Topic 40\n",
      "['elsa', 'jaggard', 'meghan', 'forester', 'georgiana']\n",
      "====================\n",
      "\n",
      "Topic 41\n",
      "['eleventh', 'ninth', 'thirtieth', 'seventh', 'warmest']\n",
      "====================\n",
      "\n",
      "Topic 42\n",
      "['fend', 'prolonging', 'narcotrafficking', 'intensifies', 'succumbing']\n",
      "====================\n",
      "\n",
      "Topic 43\n",
      "['lagrange', 'thermodynamics', 'schmoke', 'durango', 'wiegele']\n",
      "====================\n",
      "\n",
      "Topic 44\n",
      "['tanzanian', 'zambian', 'ibadan', 'bangladeshi', 'gaspare']\n",
      "====================\n",
      "\n",
      "Topic 45\n",
      "['cummins', 'matty', 'sherbert', 'calloway', 'laps']\n",
      "====================\n",
      "\n",
      "Topic 46\n",
      "['titus', 'constantine', 'mourad', 'syrus', 'theodoros']\n",
      "====================\n",
      "\n",
      "Topic 47\n",
      "['municipal', 'cbc', 'unaffiliated', 'undertakings', 'municipalities']\n",
      "====================\n",
      "\n",
      "Topic 48\n",
      "['cornell', 'chair', 'tufts', 'reed', 'luncheon']\n",
      "====================\n",
      "\n",
      "Topic 49\n",
      "['engender', 'opposites', 'receptivity', 'longshot', 'altruism']\n",
      "====================\n",
      "\n",
      "Topic 50\n",
      "['ebadi', 'submitted', 'wiesel', 'authenticated', 'hwang']\n",
      "====================\n",
      "\n",
      "Topic 51\n",
      "['sharen', 'dusenbury', 'poirier', 'michale', 'feustel']\n",
      "====================\n",
      "\n",
      "Topic 52\n",
      "['patenting', 'decapitation', 'unauthorized', 'infringing', 'premarket']\n",
      "====================\n",
      "\n",
      "Topic 53\n",
      "['rocketry', 'atheists', 'enthusiasts', 'proscribed', 'hobbyists']\n",
      "====================\n",
      "\n",
      "Topic 54\n",
      "['chinook', 'chopper', 'tans', 'flatback', 'iceberg']\n",
      "====================\n",
      "\n",
      "Topic 55\n",
      "['hubbs', 'fritts', 'thon', 'cahn', 'baeck']\n",
      "====================\n",
      "\n",
      "Topic 56\n",
      "['thermobaric', 'retreads', 'rosenbergs', 'servicewomen', 'throwaways']\n",
      "====================\n",
      "\n",
      "Topic 57\n",
      "['showered', 'spared', 'padang', 'reap', 'bathed']\n",
      "====================\n",
      "\n",
      "Topic 58\n",
      "['ppi', 'rem', 'pv', 'subsets', 'adp']\n",
      "====================\n",
      "\n",
      "Topic 59\n",
      "['accountancy', 'bdo', 'pricewaterhousecoopers', 'actuarial', 'icf']\n",
      "====================\n",
      "\n",
      "Topic 60\n",
      "['adulterating', 'harmer', 'currie', 'incubate', 'fattal']\n",
      "====================\n",
      "\n",
      "Topic 61\n",
      "['henrik', 'sabo', 'magnus', 'jonsson', 'trimester']\n",
      "====================\n",
      "\n",
      "Topic 62\n",
      "['dirge', 'verities', 'beatle', 'clunker', 'acolyte']\n",
      "====================\n",
      "\n",
      "Topic 63\n",
      "['beit', 'tryouts', 'skeet', 'kalma', 'roosters']\n",
      "====================\n",
      "\n",
      "Topic 64\n",
      "['devalued', 'stamps', 'romanovs', 'brides', 'wallets']\n",
      "====================\n",
      "\n",
      "Topic 65\n",
      "['inr', 'dosage', 'pemaquid', 'heave', 'ct']\n",
      "====================\n",
      "\n",
      "Topic 66\n",
      "['resigns', 'chairmanship', 'proxy', 'dccc', 'cfo']\n",
      "====================\n",
      "\n",
      "Topic 67\n",
      "['trial', 'paternity', 'proceedings', 'lodged', 'removed']\n",
      "====================\n",
      "\n",
      "Topic 68\n",
      "['escort', 'departed', 'anchored', 'raf', 'destroyers']\n",
      "====================\n",
      "\n",
      "Topic 69\n",
      "['plumbing', 'cowher', 'wiring', 'rinks', 'mondale']\n",
      "====================\n",
      "\n",
      "Topic 70\n",
      "['grossing', 'converter', 'flop', 'dud', 'flatscreen']\n",
      "====================\n",
      "\n",
      "Topic 71\n",
      "['khalfan', 'ingredient', 'enhancer', 'vitamins', 'pee']\n",
      "====================\n",
      "\n",
      "Topic 72\n",
      "['tailpipe', 'emissions', 'emission', 'ratifies', 'greenhouse']\n",
      "====================\n",
      "\n",
      "Topic 73\n",
      "['mollie', 'tonsils', 'abdicated', 'postmaster', 'duy']\n",
      "====================\n",
      "\n",
      "Topic 74\n",
      "['crematoria', 'dor', 'efraim', 'dominique', 'ritter']\n",
      "====================\n",
      "\n",
      "Topic 75\n",
      "['quan', 'pestis', 'liao', 'xiaomei', 'batista']\n",
      "====================\n",
      "\n",
      "Topic 76\n",
      "['neiman', 'names', 'executive', 'chief', 'cater']\n",
      "====================\n",
      "\n",
      "Topic 77\n",
      "['deboer', 'stimpson', 'hightower', 'sory', 'bittner']\n",
      "====================\n",
      "\n",
      "Topic 78\n",
      "['eurovision', 'ff', 'itf', 'mcc', 'vawa']\n",
      "====================\n",
      "\n",
      "Topic 79\n",
      "['silvers', 'mm', 'billon', 'golds', 'bests']\n",
      "====================\n",
      "\n",
      "Topic 80\n",
      "['blakeley', 'cassella', 'mixon', 'lanman', 'mose']\n",
      "====================\n",
      "\n",
      "Topic 81\n",
      "['peo', 'rosada', 'insurer', 'cosco', 'truckstop']\n",
      "====================\n",
      "\n",
      "Topic 82\n",
      "['ibsen', 'daphne', 'viareggio', 'italiana', 'metamorphosis']\n",
      "====================\n",
      "\n",
      "Topic 83\n",
      "['collision', 'causative', 'associated', 'interactions', 'reaction']\n",
      "====================\n",
      "\n",
      "Topic 84\n",
      "['imes', 'jaleel', 'rhatigan', 'reas', 'arman']\n",
      "====================\n",
      "\n",
      "Topic 85\n",
      "['inheritance', 'divestiture', 'reorganization', 'warranty', 'motherhood']\n",
      "====================\n",
      "\n",
      "Topic 86\n",
      "['minting', 'pegs', 'budge', 'graphite', 'talat']\n",
      "====================\n",
      "\n",
      "Topic 87\n",
      "['mig', 'airplanes', 'ultralight', 'aircrafts', 'handguns']\n",
      "====================\n",
      "\n",
      "Topic 88\n",
      "['agile', 'weevil', 'rider', 'unstoppable', 'ridden']\n",
      "====================\n",
      "\n",
      "Topic 89\n",
      "['variations', 'spellings', 'aforementioned', 'n', 'newton']\n",
      "====================\n",
      "\n",
      "Topic 90\n",
      "['harlow', 'hellman', 'perella', 'swanton', 'zichron']\n",
      "====================\n",
      "\n",
      "Topic 91\n",
      "['giovanni', 'giordano', 'timers', 'egghead', 'obeys']\n",
      "====================\n",
      "\n",
      "Topic 92\n",
      "['interstates', 'operate', 'stations', 'operates', 'mandates']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "\n",
      "Topic 93\n",
      "['tabulating', 'chairmanships', 'retakes', 'iaf', 'mustering']\n",
      "====================\n",
      "\n",
      "Topic 94\n",
      "['piqued', 'gushing', 'koontz', 'genuineness', 'aquifer']\n",
      "====================\n",
      "\n",
      "Topic 95\n",
      "['seasonally', 'depreciated', 'franc', 'logged', 'overvalued']\n",
      "====================\n",
      "\n",
      "Topic 96\n",
      "['combatants', 'possess', 'legally', 'consume', 'personas']\n",
      "====================\n",
      "\n",
      "Topic 97\n",
      "['organizes', 'departmental', 'secretarial', 'prek', 'curricular']\n",
      "====================\n",
      "\n",
      "Topic 98\n",
      "['redacted', 'vinyl', 'processed', 'keys', 'notices']\n",
      "====================\n",
      "\n",
      "Topic 99\n",
      "['zyed', 'hasbrouck', 'maries', 'noninterest', 'goring']\n"
     ]
    }
   ],
   "source": [
    "rmn.inspect_topics(k_neighbors = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transpose_29:0' shape=(100, 50) dtype=float32>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = K.transpose(rmn.model.get_layer(\"Wd\").get_weights()[0])\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_36:0' shape=(100, 50) dtype=float32>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = K.constant(rmn.model.get_layer(\"R\").get_weights()[0])\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orthogonality penalty\n",
    "RR_t = K.dot(R, K.transpose(R))\n",
    "Id_mat = K.eye(rmn.num_topics)\n",
    "orth_penalty = K.sqrt(K.sum(K.square(RR_t - Id_mat)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.2372"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.get_value(orth_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3391.5718"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.get_value(K.sum(K.square(RR_t - Id_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.keras.api._v1.keras.backend' has no attribute 'norm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-bcae0d227c70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRR_t\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mId_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/module_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m       \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_public_apis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.keras.api._v1.keras.backend' has no attribute 'norm'"
     ]
    }
   ],
   "source": [
    "K.get_value(K.norm(RR_t - Id_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul_7:0' shape=(100, 100) dtype=float32>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RR_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_3:0' shape=(100, 100) dtype=float32>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Id_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sub_12:0' shape=(100, 100) dtype=float32>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RR_t - Id_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
