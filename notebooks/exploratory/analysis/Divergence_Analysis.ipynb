{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/rocassius/w266_final/scripts/assembly\")\n",
    "from constant import DOC_SAMPLE_PATH, DOC_PROPER_PATH\n",
    "from document import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_documents(sessions=list(range(104,105)), read_path=DOC_PROPER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/rocassius/w266_final/scripts/modeling\")\n",
    "from rmn import *\n",
    "from rmn_data_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rocassius/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/rocassius/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "rmn = RMN()\n",
    "rmn.load_rmn(name=\"half\", save_path = \"/home/rocassius/gen-data/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samp = df.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_preds = rmn.predict_topics(df_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = RMN_DataGenerator(rmn, df_samp, batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make topic predictions\n",
    "# topics_preds = rmn.topic_model.predict_generator(dg, use_multiprocessing=True, workers=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "REP = \"R\"\n",
    "DEM = \"D\"\n",
    "PARTY = \"party\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import rel_entr\n",
    "\n",
    "def jensenshannon(p, q, base=None):\n",
    "    \"\"\"\n",
    "    Returns the JS divergence between two 1-dimensional probability vectors\n",
    "    code taken from scipy and modified to fix bug\n",
    "    \n",
    "    \"\"\"\n",
    "    p = np.asarray(p)\n",
    "    q = np.asarray(q)\n",
    "    p = p / np.sum(p, axis=0)\n",
    "    q = q / np.sum(q, axis=0)\n",
    "    m = (p + q) / 2.0\n",
    "    left = rel_entr(p, m)\n",
    "    right = rel_entr(q, m)\n",
    "    js = max(0, np.sum(left, axis=0) + np.sum(right, axis=0))\n",
    "    if base is not None:\n",
    "        js /= np.log(base)\n",
    "    return np.sqrt(js / 2.0)\n",
    "\n",
    "\n",
    "def mean_js_div(p1, p2, base=2):\n",
    "    \"\"\"\n",
    "    Compute mean JS divergence between two list of probability distributions\n",
    "    \"\"\"\n",
    "    mean_js = np.mean([jensenshannon(p, q, base) for p, q in zip(p1, p2)])\n",
    "    \n",
    "    return mean_js\n",
    "\n",
    "\n",
    "def expected_div(df1, df2=None):\n",
    "\n",
    "    if df2 is None: \n",
    "        df_A, df_B = df1[::2], df1[1::2]\n",
    "    else:           \n",
    "        df_A, df_B = df1, df2\n",
    "    \n",
    "    return mean_js_div(rmn.predict_topics(df_A), rmn.predict_topics(df_B))\n",
    "    \n",
    "    \n",
    "def compute_diversity_scores(df):\n",
    "    \n",
    "    # sample\n",
    "    d = blocked_sample(df, col=\"party\", size=1)\n",
    "    d = df\n",
    "    # identify party members\n",
    "    rep_df = d[d[PARTY] == REP]\n",
    "    dem_df = d[d[PARTY] == DEM]\n",
    "    \n",
    "    div = {'inter_div': expected_div(rep_df, dem_df),\n",
    "           'rep_div':   expected_div(rep_df),\n",
    "           'dem_div':   expected_div(dem_df)}\n",
    "    \n",
    "    return div\n",
    "\n",
    "\n",
    "def blocked_sample(df, col, size):\n",
    "    \"\"\"\n",
    "    Returns a blocked random sample from df blocked on col.\n",
    "    \"\"\"\n",
    "    return  df.groupby(col, as_index=False) \\\n",
    "              .apply(lambda d: d.sample(size)) \\\n",
    "              .sample(frac=1)\n",
    "\n",
    "\n",
    "# Herfindahlâ€“Hirschman Index\n",
    "def hh_index(p):\n",
    "    \n",
    "    p = np.asarray(p)\n",
    "    p = p / np.sum(p)\n",
    "    hhi = np.sum(p**2)\n",
    "    return hhi\n",
    "\n",
    "\n",
    "def intra_div(p_list):\n",
    "    \n",
    "    hh_indices = [hh_index(p) for p in p_list]\n",
    "    div = 1 - np.log(np.mean(hh_indicies))\n",
    "    \n",
    "    return div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 'minorities'\n",
    "\n",
    "SUB_KEY = 'subject'\n",
    "SPEAKER = 'speakerid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inter_div': 0.07909239252182533,\n",
       " 'rep_div': 0.0785186946240704,\n",
       " 'dem_div': 0.07986857147032105}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diversity_scores(df_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMN_Analyzer(object):\n",
    "    \n",
    "    def __init__(self, rmn, df):\n",
    "        \n",
    "        self.rmn = rmn\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.topic_preds = None\n",
    "        \n",
    "    @property\n",
    "    def index(self):\n",
    "        return self.df.index\n",
    "         \n",
    "        \n",
    "    def predict_topics(self):\n",
    "        \"\"\"Computes the topic predictions for all observations\n",
    "        \"\"\"\n",
    "        self.topic_preds = self.rmn.predict_topics(self.df)\n",
    "        \n",
    "\n",
    "    def bool_subset(self, col, value):\n",
    "        \"\"\"\n",
    "        Returns a boolean vector for each observation in the\n",
    "        dataframe indicating whether it meets the conditions\n",
    "        \"\"\"\n",
    "        return self.df[col] == value\n",
    "    \n",
    "    \n",
    "    def sample_indices(self, indices, n):\n",
    "        \"\"\"Returns a SRR of the indices provided\n",
    "        \"\"\"\n",
    "        return np.random.choice(indices, n, replace=True)\n",
    "    \n",
    "    \n",
    "    def inter_group_divergence(self, index_A, index_B):\n",
    "        \"\"\"\n",
    "        Returns the mean pairwise JS-divergence between topic predictions\n",
    "        associated with sample1 and those associated with sample2\n",
    "        \"\"\"\n",
    "        div = mean_js_div(self.topic_preds[index_A], \n",
    "                          self.topic_preds[index_B])\n",
    "        \n",
    "        return div\n",
    "          \n",
    "    \n",
    "    def intra_party_divergence(self, party, subject, n):\n",
    "        \"\"\"\n",
    "        Returns the intraparty divergence for a given party \n",
    "        on a given subject\n",
    "        \n",
    "        Args:\n",
    "        subject: (str) subject to examine\n",
    "        party  : (str) party of interest\n",
    "        n      : (int) sample size\n",
    "        \"\"\"\n",
    "        # ensure that the topic predictions exist\n",
    "        if self.topic_preds is None:\n",
    "            self.predict_topics()\n",
    "        \n",
    "        # find party indicies on the subject\n",
    "        party_index = self.index[self.bool_subset(PARTY, party) & \n",
    "                                 self.bool_subset(SUB_KEY, subject)]\n",
    "        \n",
    "        # Return none if there are fewer than 2 speakers\n",
    "        if self.df.loc[party_index][SPEAKER].nunique() < 2:\n",
    "            return None\n",
    "        \n",
    "        # Sample index pairs\n",
    "        index_AB = []\n",
    "        while len(index_AB) < n:\n",
    "            a_b = self.sample_indices(party_index, n=2)\n",
    "            # include pairs whose speakers are different\n",
    "            if self.df.loc[a_b][SPEAKER].nunique() == 2:\n",
    "                index_AB.append(a_b)\n",
    "        \n",
    "        index_AB = np.asarray(index_AB)\n",
    "        assert index_AB.shape == (n, 2)\n",
    "        \n",
    "        # get indices for each group\n",
    "        index_A, index_B = index_AB[:,0], index_AB[:,1]\n",
    "        \n",
    "        return self.inter_group_divergence(index_A, index_B)\n",
    "    \n",
    "    \n",
    "    def inter_party_divergence(self, subject, n):\n",
    "        \"\"\"\n",
    "        Returns the interparty divergence between Republicans and Democrats\n",
    "        on a given subject\n",
    "        \n",
    "        Args:\n",
    "        subject: (str) subject to examine\n",
    "        n      : (int) sample size\n",
    "        \"\"\"\n",
    "        # ensure that the topic predictions exist\n",
    "        if self.topic_preds is None:\n",
    "            self.predict_topics()\n",
    "        \n",
    "        # find R and D indicies on the subject\n",
    "        is_subject = self.bool_subset(SUB_KEY, subject)\n",
    "        index_R = self.index[self.bool_subset(PARTY, REP) & is_subject]\n",
    "        index_D = self.index[self.bool_subset(PARTY, DEM) & is_subject]\n",
    "        \n",
    "        # return None if indices are insufficient\n",
    "        if len(index_R)==0 or len(index_D)==0:\n",
    "            return None\n",
    "        \n",
    "        # sample \n",
    "        samp_index_R = self.sample_indices(index_R, n)\n",
    "        samp_index_D = self.sample_indices(index_D, n)\n",
    "    \n",
    "        return self.inter_group_divergence(samp_index_R, samp_index_D)\n",
    "    \n",
    "    \n",
    "#    def intra_party_diversity(self, subject, n):\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame({'a': [], 'b': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"b\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = RMN_Analyzer(rmn, df_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzer.predict_topics()\n",
    "analyzer.topic_preds = topics_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08154862785029093"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.inter_party_divergence('abortion', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07846073805828929"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.intra_party_divergence('R', 'abortion',  10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07827038726984283"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samp.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
